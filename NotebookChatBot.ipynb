{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch transformers sentence-transformers numpy nltk spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola, ¿en qué puedo ayudarte?\n",
      "Chatbot: ¡Hola! ¿Cómo puedo ayudarte?\n",
      "Chatbot: ¡Hola! ¿Cómo puedo ayudarte?\n",
      "Chatbot: ¡Hola! ¿Cómo puedo ayudarte?\n",
      "Chatbot:  Have you ever been to Buen Duel? It's a Mexican soccer tournament.\n",
      "Chatbot:  Have you ever been to Buen Diego? It's an island in the Caribbean Sea.\n",
      "Chatbot:  Have you ever been to Buenos Divide? It's a city in Las Vegas, Nevada.\n",
      "Chatbot:  Have you ever been to Buenos Divide? It's a city in Las Vegas, Nevada.\n",
      "Chatbot: ¡Hola! ¿Cómo puedo ayudarte?\n",
      "Chatbot: ¡Entendido! Dime tus preferencias y te recomendaré un celular.\n",
      "Chatbot: ¿Te interesa que tenga una batería de larga duración?\n",
      "Chatbot: ¿Cuánto es tu presupuesto máximo?\n",
      "Chatbot: ¿Qué marca prefieres?\n",
      "Chatbot: ¿Quieres una buena cámara?\n",
      "Chatbot: ¿Necesitas un celular con buen rendimiento?\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'precio'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 122\u001b[39m\n\u001b[32m    119\u001b[39m             preferencias_usuario.clear()\n\u001b[32m    120\u001b[39m             indice_pregunta = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m \u001b[43mchatbot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 112\u001b[39m, in \u001b[36mchatbot\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    110\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mChatbot: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpreguntas_flujo[indice_pregunta][\u001b[33m'\u001b[39m\u001b[33mpregunta\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     celular_recomendado = \u001b[43mrecomendar_celular\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m celular_recomendado:\n\u001b[32m    114\u001b[39m         respuesta = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTe recomiendo el \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcelular_recomendado[\u001b[33m'\u001b[39m\u001b[33mnombre\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m que cuesta $\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcelular_recomendado[\u001b[33m'\u001b[39m\u001b[33mprecio\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m y tiene una cámara de \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcelular_recomendado[\u001b[33m'\u001b[39m\u001b[33mcamara\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mMP.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mrecomendar_celular\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m clave, valor \u001b[38;5;129;01min\u001b[39;00m preferencias_usuario.items():\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m clave == \u001b[33m\"\u001b[39m\u001b[33mpresupuesto\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m         celulares_filtrados = [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m celulares_filtrados \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mc\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprecio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m <= valor]\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m clave == \u001b[33m\"\u001b[39m\u001b[33mcamara\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     62\u001b[39m         celulares_filtrados = [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m celulares_filtrados \u001b[38;5;28;01mif\u001b[39;00m c[\u001b[33m\"\u001b[39m\u001b[33mcamara\u001b[39m\u001b[33m\"\u001b[39m] >= valor]\n",
      "\u001b[31mKeyError\u001b[39m: 'precio'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import spacy\n",
    "from collections import deque\n",
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
    "\n",
    "# Cargar el modelo de Blenderbot\n",
    "model_name = \"facebook/blenderbot-400M-distill\"\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained(model_name)\n",
    "model = BlenderbotForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Cargar intents\n",
    "with open(\"intents.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    intents = json.load(file)\n",
    "\n",
    "# Cargar datos de celulares\n",
    "with open(\"celulares_limpios.json\", \"r\", encoding=\"utf-8\") as file:\n",
    "    celulares = json.load(file)\n",
    "\n",
    "# Memoria del chatbot\n",
    "memoria_chat = deque(maxlen=5)\n",
    "preferencias_usuario = {}\n",
    "inicio_recoleccion = False\n",
    "preguntas_flujo = [\n",
    "    {\"clave\": \"bateria\", \"pregunta\": \"¿Te interesa que tenga una batería de larga duración?\"},\n",
    "    {\"clave\": \"presupuesto\", \"pregunta\": \"¿Cuánto es tu presupuesto máximo?\"},\n",
    "    {\"clave\": \"marca\", \"pregunta\": \"¿Qué marca prefieres?\"},\n",
    "    {\"clave\": \"camara\", \"pregunta\": \"¿Quieres una buena cámara?\"},\n",
    "    {\"clave\": \"rendimiento\", \"pregunta\": \"¿Necesitas un celular con buen rendimiento?\"}\n",
    "]\n",
    "indice_pregunta = 0\n",
    "\n",
    "# Cargar modelo de lenguaje para extraer palabras clave\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "def extraer_palabras_clave(texto):\n",
    "    doc = nlp(texto)\n",
    "    palabras_clave = [token.lemma_ for token in doc if token.pos_ in [\"NOUN\", \"ADJ\", \"VERB\", \"NUM\"]]\n",
    "    return palabras_clave\n",
    "\n",
    "def buscar_intent(mensaje):\n",
    "    mensaje_procesado = \" \".join(extraer_palabras_clave(mensaje))\n",
    "    for intent in intents[\"intents\"]:\n",
    "        for pattern in intent[\"patterns\"]:\n",
    "            if pattern.lower() in mensaje_procesado.lower():\n",
    "                return intent[\"responses\"]\n",
    "    return None\n",
    "\n",
    "def generar_respuesta(mensaje):\n",
    "    memoria_chat.append(mensaje)\n",
    "    mensaje_contexto = \" \".join(memoria_chat)\n",
    "    inputs = tokenizer([mensaje_contexto], return_tensors=\"pt\")\n",
    "    reply_ids = model.generate(**inputs)\n",
    "    respuesta = tokenizer.decode(reply_ids[0], skip_special_tokens=True)\n",
    "    return respuesta\n",
    "\n",
    "def recomendar_celular():\n",
    "    celulares_filtrados = celulares\n",
    "    for clave, valor in preferencias_usuario.items():\n",
    "        if clave == \"presupuesto\":\n",
    "            celulares_filtrados = [c for c in celulares_filtrados if c[\"precio\"] <= valor]\n",
    "        elif clave == \"camara\":\n",
    "            celulares_filtrados = [c for c in celulares_filtrados if c[\"camara\"] >= valor]\n",
    "        elif clave == \"rendimiento\":\n",
    "            celulares_filtrados = [c for c in celulares_filtrados if c[\"ram\"] >= valor]\n",
    "        elif clave == \"bateria\":\n",
    "            celulares_filtrados = [c for c in celulares_filtrados if c[\"bateria\"] >= valor]\n",
    "        elif clave == \"marca\":\n",
    "            celulares_filtrados = [c for c in celulares_filtrados if valor.lower() in c[\"marca\"].lower()]\n",
    "    return celulares_filtrados[0] if celulares_filtrados else None\n",
    "\n",
    "def chatbot():\n",
    "    global inicio_recoleccion, preferencias_usuario, indice_pregunta\n",
    "    print(\"Hola, ¿en qué puedo ayudarte?\")\n",
    "    while True:\n",
    "        user_input = input(\"Tú: \")\n",
    "        if user_input.lower() == \"salir\":\n",
    "            print(\"Chatbot: ¡Hasta luego!\")\n",
    "            break\n",
    "        \n",
    "        if not inicio_recoleccion:\n",
    "            intent_respuesta = buscar_intent(user_input)\n",
    "            if intent_respuesta:\n",
    "                print(f\"Chatbot: {intent_respuesta[0]}\")\n",
    "            elif \"recomendar\" in user_input.lower() or \"celular\" in user_input.lower():\n",
    "                inicio_recoleccion = True\n",
    "                indice_pregunta = 0\n",
    "                preferencias_usuario.clear()\n",
    "                print(\"Chatbot: ¡Entendido! Dime tus preferencias y te recomendaré un celular.\")\n",
    "                print(f\"Chatbot: {preguntas_flujo[indice_pregunta]['pregunta']}\")\n",
    "            else:\n",
    "                print(f\"Chatbot: {generar_respuesta(user_input)}\")\n",
    "            continue\n",
    "        \n",
    "        clave_pregunta_actual = preguntas_flujo[indice_pregunta][\"clave\"]\n",
    "        \n",
    "        if \"sí\" in user_input.lower() or \"claro\" in user_input.lower():\n",
    "            preferencias_usuario[clave_pregunta_actual] = 4000 if clave_pregunta_actual == \"bateria\" else 1\n",
    "        elif \"no\" in user_input.lower():\n",
    "            pass\n",
    "        else:\n",
    "            palabras_clave = extraer_palabras_clave(user_input)\n",
    "            for palabra in palabras_clave:\n",
    "                if palabra.isdigit():\n",
    "                    preferencias_usuario[clave_pregunta_actual] = int(palabra)\n",
    "                else:\n",
    "                    preferencias_usuario[clave_pregunta_actual] = palabra\n",
    "        \n",
    "        indice_pregunta += 1\n",
    "        if indice_pregunta < len(preguntas_flujo):\n",
    "            print(f\"Chatbot: {preguntas_flujo[indice_pregunta]['pregunta']}\")\n",
    "        else:\n",
    "            celular_recomendado = recomendar_celular()\n",
    "            if celular_recomendado:\n",
    "                respuesta = f\"Te recomiendo el {celular_recomendado['Model Name']} que cuesta ${celular_recomendado['Launched Price (USA)']}, tiene una cámara de {celular_recomendado['Front Camera (MP)']}MP y una cámara trasera de{celular_recomendado['Back Camera (MP)']}.\"\n",
    "            else:\n",
    "                respuesta = \"No encontré un celular que cumpla con todas tus preferencias.\"\n",
    "            print(f\"Chatbot: {respuesta}\")\n",
    "            inicio_recoleccion = False\n",
    "            preferencias_usuario.clear()\n",
    "            indice_pregunta = 0\n",
    "\n",
    "chatbot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
