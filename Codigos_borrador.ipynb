{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "OC9VNnxVNs_f",
        "outputId": "de9508f7-1b56-4548-ae4e-0fd12076f9e7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-58d90693-7d02-4433-90be-9c2160800c3d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-58d90693-7d02-4433-90be-9c2160800c3d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving celulares_limpios.json to celulares_limpios.json\n",
            "Saving intents.json to intents.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "O5pRnHKqYxDA",
        "outputId": "92c94f8b-bd15-44cb-ed24-32e214e9f3e3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ddb71f91-c11d-435d-81ab-99182540418c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ddb71f91-c11d-435d-81ab-99182540418c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving IntentosXEficiencia.json to IntentosXEficiencia (1).json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "codigo origen corriendo"
      ],
      "metadata": {
        "id": "4QB4wPFnkZcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC  # ðŸ“Œ Mejor clasificador que KNN\n",
        "\n",
        "# ðŸ“Œ Cargar modelos de Hugging Face\n",
        "modelo_emb_name = \"distilbert-base-uncased\"  # Modelo para obtener embeddings\n",
        "modelo_resp_name = \"facebook/blenderbot-400M-distill\"  # Modelo para generar respuestas\n",
        "\n",
        "tokenizer_emb = AutoTokenizer.from_pretrained(modelo_emb_name)\n",
        "modelo_emb = AutoModel.from_pretrained(modelo_emb_name)\n",
        "\n",
        "tokenizer_resp = AutoTokenizer.from_pretrained(modelo_resp_name)\n",
        "modelo_resp = AutoModelForSeq2SeqLM.from_pretrained(modelo_resp_name)\n",
        "\n",
        "# ðŸ“Œ Cargar el dataset del chatbot (intents.json)\n",
        "archivo_intents = \"intents.json\"\n",
        "try:\n",
        "    with open(archivo_intents, \"r\", encoding=\"utf-8\") as file:\n",
        "        intents = json.load(file)\n",
        "except FileNotFoundError:\n",
        "    intents = {\"intents\": []}\n",
        "\n",
        "# ðŸ“Œ Cargar dataset de celulares\n",
        "archivo_celulares = \"celulares_limpios.json\"\n",
        "try:\n",
        "    with open(archivo_celulares, \"r\", encoding=\"utf-8\") as file:\n",
        "        celulares = json.load(file)\n",
        "except FileNotFoundError:\n",
        "    celulares = []\n",
        "\n",
        "# ðŸ“Œ Memoria de la conversaciÃ³n (para recordar contexto)\n",
        "memoria_chat = []\n",
        "\n",
        "def obtener_embedding(frase):\n",
        "    tokens = tokenizer_emb(frase, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
        "    with torch.no_grad():\n",
        "        salida = modelo_emb(**tokens)\n",
        "    return salida.last_hidden_state[:, 0, :].numpy().flatten()\n",
        "\n",
        "patterns, labels = [], []\n",
        "\n",
        "for intent in intents[\"intents\"]:\n",
        "    if \"tag\" in intent and \"patterns\" in intent:\n",
        "        for pattern in intent[\"patterns\"]:\n",
        "            patterns.append(pattern)\n",
        "            labels.append(intent[\"tag\"])\n",
        "\n",
        "\n",
        "if patterns:\n",
        "    X = np.array([obtener_embedding(frase) for frase in patterns])\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(labels)\n",
        "\n",
        "    classifier = SVC(kernel=\"linear\", probability=True)\n",
        "    classifier.fit(X, y)\n",
        "else:\n",
        "    classifier = None\n",
        "\n",
        "def predecir_intencion(frase):\n",
        "    if classifier:\n",
        "        embedding = obtener_embedding(frase)\n",
        "        prediccion = classifier.predict([embedding])[0]\n",
        "        return label_encoder.inverse_transform([prediccion])[0]\n",
        "    return None\n",
        "\n",
        "def obtener_respuesta_json(intencion):\n",
        "    for intent in intents[\"intents\"]:\n",
        "        if intent[\"tag\"] == intencion:\n",
        "            return np.random.choice(intent[\"responses\"])\n",
        "    return None\n",
        "\n",
        "def generar_respuesta_transformer(frase):\n",
        "    tokens = tokenizer_resp(frase, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
        "    with torch.no_grad():\n",
        "        respuesta_ids = modelo_resp.generate(**tokens)\n",
        "    return tokenizer_resp.decode(respuesta_ids[0], skip_special_tokens=True)\n",
        "\n",
        "def respuesta_valida(respuesta):\n",
        "    palabras_invalidas = [\"no sÃ©\", \"no entiendo\", \"no puedo ayudar\", \"no tengo informaciÃ³n\"]\n",
        "    return not any(palabra in respuesta.lower() for palabra in palabras_invalidas)\n",
        "\n",
        "def guardar_aprendizaje(nueva_pregunta, nueva_respuesta):\n",
        "    global intents\n",
        "\n",
        "    if not respuesta_valida(nueva_respuesta):\n",
        "        return\n",
        "\n",
        "    intencion_predicha = predecir_intencion(nueva_pregunta)\n",
        "\n",
        "    if intencion_predicha:\n",
        "        for intent in intents[\"intents\"]:\n",
        "            if intent[\"tag\"] == intencion_predicha:\n",
        "                if nueva_pregunta not in intent[\"patterns\"]:\n",
        "                    intent[\"patterns\"].append(nueva_pregunta)\n",
        "                if nueva_respuesta not in intent[\"responses\"]:\n",
        "                    intent[\"responses\"].append(nueva_respuesta)\n",
        "                break\n",
        "    else:\n",
        "        nueva_categoria = f\"aprendizaje_{len(intents['intents'])+1}\"\n",
        "        intents[\"intents\"].append({\n",
        "            \"tag\": nueva_categoria,\n",
        "            \"patterns\": [nueva_pregunta],\n",
        "            \"responses\": [nueva_respuesta]\n",
        "        })\n",
        "\n",
        "    with open(archivo_intents, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(intents, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "def manejar_contexto(texto):\n",
        "    global memoria_chat\n",
        "    memoria_chat.append(texto)\n",
        "    if len(memoria_chat) > 3:\n",
        "        memoria_chat.pop(0)\n",
        "    return \" \".join(memoria_chat)\n",
        "\n",
        "def responder_chatbot(texto):\n",
        "    texto_con_contexto = manejar_contexto(texto)\n",
        "    intencion = predecir_intencion(texto_con_contexto)\n",
        "    respuesta = obtener_respuesta_json(intencion)\n",
        "\n",
        "    if respuesta:\n",
        "        return respuesta\n",
        "\n",
        "    for celular in celulares:\n",
        "        if any(palabra in texto.lower() for palabra in [celular[\"Company Name\"].lower(), celular[\"Model Name\"].lower()]):\n",
        "            return json.dumps(celular, indent=4)\n",
        "\n",
        "    respuesta_generada = generar_respuesta_transformer(texto_con_contexto)\n",
        "\n",
        "    if respuesta_valida(respuesta_generada):\n",
        "        guardar_aprendizaje(texto, respuesta_generada)\n",
        "\n",
        "    return respuesta_generada\n",
        "\n",
        "while True:\n",
        "    pregunta = input(\"ðŸ‘¤ Escribe tu consulta (o 'salir' para terminar): \")\n",
        "    if pregunta.lower() == \"salir\":\n",
        "        break\n",
        "    print(\"ðŸ¤–\", responder_chatbot(pregunta))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXBjzj4JQrfO",
        "outputId": "41f53551-b5c5-4723-dadb-9afdf9ff61f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ‘¤ Escribe tu consulta (o 'salir' para terminar): Â¿cuÃ¡l es el mejor celular para gaming'\n",
            "ðŸ¤– Â¡CuÃ­date!\n",
            "ðŸ‘¤ Escribe tu consulta (o 'salir' para terminar): celular barato\n",
            "ðŸ¤– Los telÃ©fonos con Snapdragon 8 Gen 2 y buena tasa de refresco son ideales para juegos.\n",
            "ðŸ‘¤ Escribe tu consulta (o 'salir' para terminar): telefono para jugar\n",
            "ðŸ¤– Â¿Tienes un presupuesto en mente? Puedo recomendarte algo segÃºn tu rango de precio.\n",
            "ðŸ‘¤ Escribe tu consulta (o 'salir' para terminar): mil dolares\n",
            "ðŸ¤– Para gaming, te recomiendo un celular con un buen procesador y al menos 8GB de RAM.\n",
            "ðŸ‘¤ Escribe tu consulta (o 'salir' para terminar): Conoces algun modelo en especifico?\n",
            "ðŸ¤– Busca un celular con una GPU potente y refrigeraciÃ³n eficiente.\n",
            "ðŸ‘¤ Escribe tu consulta (o 'salir' para terminar): Recomienda un telefono\n",
            "ðŸ¤– Los telÃ©fonos con Snapdragon 8 Gen 2 y buena tasa de refresco son ideales para juegos.\n",
            "ðŸ‘¤ Escribe tu consulta (o 'salir' para terminar): Modelo\n",
            "ðŸ¤– Busca un celular con una GPU potente y refrigeraciÃ³n eficiente.\n",
            "ðŸ‘¤ Escribe tu consulta (o 'salir' para terminar): pantalla\n",
            "ðŸ¤– Si buscas un celular resistente, te recomiendo modelos con certificaciÃ³n IP68 o con protecciÃ³n militar.\n",
            "ðŸ‘¤ Escribe tu consulta (o 'salir' para terminar): bateria\n",
            "ðŸ¤– Para fotografÃ­a, te sugiero un celular con al menos 50MP en la cÃ¡mara principal y buen procesamiento de imagen.\n",
            "ðŸ‘¤ Escribe tu consulta (o 'salir' para terminar): Fotografia\n",
            "ðŸ¤– Para fotografÃ­a, te sugiero un celular con al menos 50MP en la cÃ¡mara principal y buen procesamiento de imagen.\n",
            "ðŸ‘¤ Escribe tu consulta (o 'salir' para terminar): Precio\n",
            "ðŸ¤– Algunos modelos cuentan con teleobjetivo para capturas a larga distancia.\n",
            "ðŸ‘¤ Escribe tu consulta (o 'salir' para terminar): costo\n",
            "ðŸ¤– Â¿Prefieres un celular con cÃ¡mara profesional o algo mÃ¡s equilibrado?\n",
            "ðŸ‘¤ Escribe tu consulta (o 'salir' para terminar): algo mÃ¡s equilibrado\n",
            "ðŸ¤– Si buscas un celular resistente, te recomiendo modelos con certificaciÃ³n IP68 o con protecciÃ³n militar.\n",
            "ðŸ‘¤ Escribe tu consulta (o 'salir' para terminar): salir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EFICIENCIA"
      ],
      "metadata": {
        "id": "Vx6TUO75QYV0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "efi1 con preguntas y respestas aleatorias esperadas"
      ],
      "metadata": {
        "id": "opKC3DqwkhPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score  # MÃ©tricas de evaluaciÃ³n\n",
        "\n",
        "# Cargar modelos de Hugging Face\n",
        "modelo_emb_name = \"distilbert-base-uncased\"\n",
        "modelo_resp_name = \"facebook/blenderbot-400M-distill\"\n",
        "\n",
        "tokenizer_emb = AutoTokenizer.from_pretrained(modelo_emb_name)\n",
        "modelo_emb = AutoModel.from_pretrained(modelo_emb_name)\n",
        "\n",
        "tokenizer_resp = AutoTokenizer.from_pretrained(modelo_resp_name)\n",
        "modelo_resp = AutoModelForSeq2SeqLM.from_pretrained(modelo_resp_name)\n",
        "\n",
        "# Cargar el dataset del chatbot (intents.json)\n",
        "archivo_intents = \"intents.json\"\n",
        "try:\n",
        "    with open(archivo_intents, \"r\", encoding=\"utf-8\") as file:\n",
        "        intents = json.load(file)\n",
        "except FileNotFoundError:\n",
        "    intents = {\"intents\": []}\n",
        "\n",
        "# Cargar dataset de celulares\n",
        "archivo_celulares = \"celulares_limpios.json\"\n",
        "try:\n",
        "    with open(archivo_celulares, \"r\", encoding=\"utf-8\") as file:\n",
        "        celulares = json.load(file)\n",
        "except FileNotFoundError:\n",
        "    celulares = []\n",
        "\n",
        "# Memoria de la conversaciÃ³n (para recordar contexto)\n",
        "memoria_chat = []\n",
        "\n",
        "def obtener_embedding(frase):\n",
        "    tokens = tokenizer_emb(frase, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
        "    with torch.no_grad():\n",
        "        salida = modelo_emb(**tokens)\n",
        "    return salida.last_hidden_state[:, 0, :].numpy().flatten()\n",
        "\n",
        "patterns, labels = [], []\n",
        "\n",
        "for intent in intents[\"intents\"]:\n",
        "    if \"tag\" in intent and \"patterns\" in intent:\n",
        "        for pattern in intent[\"patterns\"]:\n",
        "            patterns.append(pattern)\n",
        "            labels.append(intent[\"tag\"])\n",
        "\n",
        "if patterns:\n",
        "    X = np.array([obtener_embedding(frase) for frase in patterns])\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(labels)\n",
        "\n",
        "    classifier = SVC(kernel=\"linear\", probability=True)\n",
        "    classifier.fit(X, y)\n",
        "else:\n",
        "    classifier = None\n",
        "\n",
        "def predecir_intencion(frase):\n",
        "    if classifier:\n",
        "        embedding = obtener_embedding(frase)\n",
        "        prediccion = classifier.predict([embedding])[0]\n",
        "        return label_encoder.inverse_transform([prediccion])[0]\n",
        "    return None\n",
        "\n",
        "def obtener_respuesta_json(intencion):\n",
        "    for intent in intents[\"intents\"]:\n",
        "        if intent[\"tag\"] == intencion:\n",
        "            return np.random.choice(intent[\"responses\"])\n",
        "    return None\n",
        "\n",
        "def generar_respuesta_transformer(frase):\n",
        "    tokens = tokenizer_resp(frase, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
        "    with torch.no_grad():\n",
        "        respuesta_ids = modelo_resp.generate(**tokens)\n",
        "    return tokenizer_resp.decode(respuesta_ids[0], skip_special_tokens=True)\n",
        "\n",
        "def respuesta_valida(respuesta):\n",
        "    palabras_invalidas = [\"no sÃ©\", \"no entiendo\", \"no puedo ayudar\", \"no tengo informaciÃ³n\"]\n",
        "    return not any(palabra in respuesta.lower() for palabra in palabras_invalidas)\n",
        "\n",
        "def guardar_aprendizaje(nueva_pregunta, nueva_respuesta):\n",
        "    global intents\n",
        "\n",
        "    if not respuesta_valida(nueva_respuesta):\n",
        "        return\n",
        "\n",
        "    intencion_predicha = predecir_intencion(nueva_pregunta)\n",
        "\n",
        "    if intencion_predicha:\n",
        "        for intent in intents[\"intents\"]:\n",
        "            if intent[\"tag\"] == intencion_predicha:\n",
        "                if nueva_pregunta not in intent[\"patterns\"]:\n",
        "                    intent[\"patterns\"].append(nueva_pregunta)\n",
        "                if nueva_respuesta not in intent[\"responses\"]:\n",
        "                    intent[\"responses\"].append(nueva_respuesta)\n",
        "                break\n",
        "    else:\n",
        "        nueva_categoria = f\"aprendizaje_{len(intents['intents'])+1}\"\n",
        "        intents[\"intents\"].append({\n",
        "            \"tag\": nueva_categoria,\n",
        "            \"patterns\": [nueva_pregunta],\n",
        "            \"responses\": [nueva_respuesta]\n",
        "        })\n",
        "\n",
        "    with open(archivo_intents, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(intents, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "def manejar_contexto(texto):\n",
        "    global memoria_chat\n",
        "    memoria_chat.append(texto)\n",
        "    if len(memoria_chat) > 3:\n",
        "        memoria_chat.pop(0)\n",
        "    return \" \".join(memoria_chat)\n",
        "\n",
        "def responder_chatbot(texto):\n",
        "    texto_con_contexto = manejar_contexto(texto)\n",
        "    intencion = predecir_intencion(texto_con_contexto)\n",
        "    respuesta = obtener_respuesta_json(intencion)\n",
        "\n",
        "    if respuesta:\n",
        "        return respuesta\n",
        "\n",
        "    for celular in celulares:\n",
        "        if any(palabra in texto.lower() for palabra in [celular[\"Company Name\"].lower(), celular[\"Model Name\"].lower()]):\n",
        "            return json.dumps(celular, indent=4)\n",
        "\n",
        "    respuesta_generada = generar_respuesta_transformer(texto_con_contexto)\n",
        "\n",
        "    if respuesta_valida(respuesta_generada):\n",
        "        guardar_aprendizaje(texto, respuesta_generada)\n",
        "\n",
        "    return respuesta_generada\n",
        "\n",
        "# FunciÃ³n para evaluar el chatbot\n",
        "def evaluar_chatbot(preguntas_evaluacion, respuestas_esperadas):\n",
        "    respuestas_predichas = [responder_chatbot(pregunta) for pregunta in preguntas_evaluacion]\n",
        "\n",
        "    # Convertir las etiquetas de texto a numÃ©ricas para la evaluaciÃ³n\n",
        "    y_true = [predecir_intencion(pregunta) for pregunta in preguntas_evaluacion]\n",
        "    y_pred = [predecir_intencion(respuesta) for respuesta in respuestas_predichas]\n",
        "\n",
        "    y_true_encoded = label_encoder.transform(y_true)\n",
        "    y_pred_encoded = label_encoder.transform(y_pred)\n",
        "\n",
        "    accuracy = accuracy_score(y_true_encoded, y_pred_encoded)\n",
        "    precision = precision_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "\n",
        "    print(f\"PrecisiÃ³n (Accuracy): {accuracy:.2f}\")\n",
        "    print(f\"PrecisiÃ³n (Precision): {precision:.2f}\")\n",
        "\n",
        "# Ejemplo de preguntas y respuestas para la evaluaciÃ³n\n",
        "preguntas_evaluacion = [\n",
        "    \"Â¿QuÃ© tipo de pantalla tiene el iPhone 13?\",\n",
        "    \"Â¿CuÃ¡nto cuesta el Samsung Galaxy S22?\",\n",
        "    \"Â¿QuÃ© procesador tiene el Xiaomi Redmi Note 11?\",\n",
        "    \"Â¿CuÃ¡ntos megapÃ­xeles tiene la cÃ¡mara del Google Pixel 6?\",\n",
        "    \"Â¿Tiene el OnePlus 10 Pro carga rÃ¡pida?\",\n",
        "    \"Â¿QuÃ© versiÃ³n de Android tiene el Samsung Galaxy A53?\",\n",
        "    \"Â¿Es resistente al agua el iPhone 13 Pro?\",\n",
        "    \"Â¿Tiene el Xiaomi 12 lector de huellas digitales?\",\n",
        "    \"Â¿QuÃ© celulares tienen 5G?\",\n",
        "    \"Â¿QuÃ© celulares tienen buena cÃ¡mara para selfies?\",\n",
        "    \"Â¿CuÃ¡l es el mejor celular para juegos?\",\n",
        "    \"Â¿QuÃ© celular tiene la mejor baterÃ­a?\",\n",
        "    \"Â¿QuÃ© celular tiene la mejor cÃ¡mara?\",\n",
        "    \"Â¿QuÃ© celular tiene la mejor pantalla?\",\n",
        "    \"Â¿QuÃ© celular es el mÃ¡s resistente?\",\n",
        "    \"Â¿QuÃ© celular tiene la mejor relaciÃ³n calidad-precio?\",\n",
        "    \"Â¿QuÃ© celular tiene la mejor conectividad?\",\n",
        "    \"Â¿QuÃ© celular tiene la mejor seguridad?\",\n",
        "    \"Â¿QuÃ© celular tiene la mejor experiencia de usuario?\",\n",
        "    \"Â¿QuÃ© celular tiene el mejor diseÃ±o?\",\n",
        "    \"Â¿QuÃ© celulares tienen pantalla AMOLED?\",\n",
        "    \"Â¿QuÃ© celulares tienen 120Hz?\",\n",
        "    \"Â¿QuÃ© celulares tienen carga inalÃ¡mbrica?\",\n",
        "    \"Â¿QuÃ© celulares tienen zoom Ã³ptico?\",\n",
        "    \"Â¿QuÃ© celulares tienen altavoces estÃ©reo?\",\n",
        "    \"Â¿QuÃ© celulares tienen jack de auriculares?\",\n",
        "    \"Â¿QuÃ© celulares tienen ranura para tarjeta microSD?\",\n",
        "    \"Â¿QuÃ© celulares tienen lÃ¡piz Ã³ptico?\",\n",
        "    \"Â¿QuÃ© celulares tienen pantalla plegable?\",\n",
        "    \"Â¿QuÃ© celulares tienen pantalla curva?\",\n",
        "    \"Â¿QuÃ© celulares tienen notch?\",\n",
        "    \"Â¿QuÃ© celulares tienen agujero en pantalla?\",\n",
        "    \"Â¿QuÃ© celulares tienen cÃ¡mara frontal debajo de la pantalla?\",\n",
        "    \"Â¿QuÃ© celulares tienen cÃ¡mara TOF?\",\n",
        "    \"Â¿QuÃ© celulares tienen sensor LiDAR?\",\n",
        "    \"Â¿QuÃ© celulares tienen sensor de ritmo cardÃ­aco?\",\n",
        "    \"Â¿QuÃ© celulares tienen sensor de temperatura?\",\n",
        "    \"Â¿QuÃ© celulares tienen sensor de luz ultravioleta?\",\n",
        "    \"Â¿QuÃ© celulares tienen sensor de huellas dactilares ultrasÃ³nico?\",\n",
        "    \"Â¿QuÃ© celulares tienen sensor de huellas dactilares Ã³ptico?\"\n",
        "]\n",
        "\n",
        "respuestas_esperadas = [\n",
        "    \"El iPhone 13 tiene una pantalla OLED Super Retina XDR de 6.1 pulgadas.\",\n",
        "    \"El precio del Samsung Galaxy S22 varÃ­a segÃºn la configuraciÃ³n, pero ronda los $799.\",\n",
        "    \"El Xiaomi Redmi Note 11 tiene un procesador Qualcomm Snapdragon 680.\",\n",
        "    \"La cÃ¡mara principal del Google Pixel 6 tiene 50 megapÃ­xeles.\",\n",
        "    \"SÃ­, el OnePlus 10 Pro tiene carga rÃ¡pida SuperVOOC de 80W.\",\n",
        "    \"El Samsung Galaxy A53 viene con Android 12.\",\n",
        "    \"SÃ­, el iPhone 13 Pro es resistente al agua con certificaciÃ³n IP68.\",\n",
        "    \"SÃ­, el Xiaomi 12 tiene lector de huellas digitales en pantalla.\",\n",
        "    \"Algunos celulares con 5G son: iPhone 13, Samsung Galaxy S22, Xiaomi 12, Google Pixel 6, OnePlus 10 Pro.\",\n",
        "    \"Algunos celulares con buena cÃ¡mara para selfies son: Google Pixel 6, iPhone 13, Samsung Galaxy S22.\",\n",
        "    \"El mejor celular para juegos depende de tus preferencias, pero algunos modelos populares son el Asus ROG Phone 6, el RedMagic 7S Pro y el iPhone 14 Pro Max.\",\n",
        "    \"El celular con la mejor baterÃ­a depende de tus necesidades, pero algunos modelos con buena autonomÃ­a son el Asus ROG Phone 6, el Motorola Edge+ y el Samsung Galaxy S23 Ultra.\",\n",
        "    \"El celular con la mejor cÃ¡mara depende de tus preferencias, pero algunos modelos con cÃ¡maras destacadas son el Google Pixel 7 Pro, el iPhone 14 Pro Max y el Samsung Galaxy S23 Ultra.\",\n",
        "    \"El celular con la mejor pantalla depende de tus preferencias, pero algunos modelos con pantallas excelentes son el Samsung Galaxy S23 Ultra, el iPhone 14 Pro Max y el Google Pixel 7 Pro.\",\n",
        "    \"El celular mÃ¡s resistente depende de tus necesidades, pero algunos modelos con buena resistencia son el CAT S62 Pro, el Samsung Galaxy XCover 6 Pro y el Doogee S100.\",\n",
        "    \"El celular con la mejor relaciÃ³n calidad-precio depende de tus necesidades y presupuesto, pero algunos modelos populares son el Google Pixel 6a, el Samsung Galaxy A53 y el Xiaomi Redmi Note 11 Pro.\",\n",
        "    \"El celular con la mejor conectividad depende de tus necesidades, pero algunos modelos con buena conectividad son el Samsung Galaxy S23 Ultra, el iPhone 14 Pro Max y el Google Pixel 7 Pro.\",\n",
        "    \"El celular con la mejor seguridad depende de tus necesidades, pero algunos modelos con buena seguridad son el Google Pixel 7 Pro, el iPhone 14 Pro Max y el Samsung Galaxy S23 Ultra.\",\n",
        "    \"El celular con la mejor experiencia de usuario depende de tus preferencias, pero algunos modelos con buena experiencia de usuario son el Google Pixel 7 Pro, el iPhone 14 Pro Max y el Samsung Galaxy S23 Ultra.\",\n",
        "    \"El celular con el mejor diseÃ±o depende de tus preferencias, pero algunos modelos con diseÃ±os atractivos son el Samsung Galaxy S23 Ultra, el iPhone 14 Pro Max y el Google Pixel 7 Pro.\",\n",
        "    \"Algunos celulares con pantalla AMOLED son: Samsung Galaxy S23 Ultra, iPhone 14 Pro Max, Google Pixel 7 Pro, OnePlus 11.\",\n",
        "    \"Algunos celulares con 120Hz son: Samsung Galaxy S23 Ultra, iPhone 14 Pro Max, Google Pixel 7 Pro, OnePlus 11, Xiaomi 13 Pro.\",\n",
        "    \"Algunos celulares con carga inalÃ¡mbrica son: Samsung Galaxy S23 Ultra, iPhone 14 Pro Max, Google Pixel 7 Pro, OnePlus 11, Xiaomi 13 Pro.\",\n",
        "    \"Algunos celulares con zoom Ã³ptico son: Samsung Galaxy S23 Ultra, iPhone 14 Pro Max, Google Pixel 7 Pro, Xiaomi 13 Pro.\",\n",
        "    \"Algunos celulares con altavoces estÃ©reo son: Samsung Galaxy S23 Ultra, iPhone 14 Pro Max, Google Pixel 7 Pro, OnePlus 11, Xiaomi 13 Pro.\",\n",
        "    \"Algunos celulares con jack de auriculares son: Asus ROG Phone 6, Sony Xperia 1 IV, algunos modelos de gama de entrada y media.\",\n",
        "    \"Algunos celulares con ranura para tarjeta microSD son: Algunos modelos de Samsung Galaxy A, algunos modelos de Xiaomi Redmi Note.\",\n",
        "    \"Algunos celulares con lÃ¡piz Ã³ptico son: Samsung Galaxy S23 Ultra, Samsung Galaxy Note 20 Ultra.\",\n",
        "    \"Algunos celulares con pantalla plegable son: Samsung Galaxy Z Fold 4, Samsung Galaxy Z Flip 4, Motorola Razr 2022.\",\n",
        "    \"Algunos celulares con pantalla curva son: Samsung Galaxy S23 Ultra, OnePlus 11, Xiaomi 13 Pro.\",\n",
        "    \"Algunos celulares con notch son: iPhone 13, iPhone 12, algunos modelos de gama de entrada y media.\",\n",
        "    \"Algunos celulares con agujero en pantalla son: Samsung Galaxy S23 Ultra, Google Pixel 7 Pro, OnePlus 11, Xiaomi 13 Pro.\",\n",
        "    \"Algunos celulares con cÃ¡mara frontal debajo de la pantalla son: Samsung Galaxy Z Fold 4, Xiaomi Mix 4.\",\n",
        "    \"Algunos celulares con cÃ¡mara TOF son: Algunos modelos de gama alta de Huawei, algunos modelos de gama alta de Samsung.\",\n",
        "    \"Algunos celulares con sensor LiDAR son: iPhone 14 Pro Max, iPhone 13 Pro Max, iPad Pro.\",\n",
        "    \"Algunos celulares con sensor de ritmo cardÃ­aco son: Algunos modelos de Samsung Galaxy Watch.\",\n",
        "    \"Algunos celulares con sensor de temperatura son: Algunos modelos de Huawei Watch.\",\n",
        "    \"Algunos celulares con sensor de luz ultravioleta son: Algunos modelos de Samsung Galaxy S.\",\n",
        "    \"Algunos celulares con sensor de huellas dactilares ultrasÃ³nico son: Samsung Galaxy S23 Ultra, Samsung Galaxy S22 Ultra.\",\n",
        "    \"Algunos celulares con sensor de huellas dactilares Ã³ptico son: Google Pixel 7 Pro, OnePlus 11, Xiaomi 13 Pro.\"\n",
        "]\n",
        "evaluar_chatbot(preguntas_evaluacion, respuestas_esperadas)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u89JRb3CQZ1R",
        "outputId": "806aa231-116b-4d58-9330-0bda01ba83ad"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PrecisiÃ³n (Accuracy): 0.80\n",
            "PrecisiÃ³n (Precision): 0.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "efi2 prueba de parametros del intents.json (la eficiencia es baja debido a que non tiene respuestas esperadas especificas)"
      ],
      "metadata": {
        "id": "5K9F6b3FkrhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score  # MÃ©tricas de evaluaciÃ³n\n",
        "\n",
        "# Cargar modelos de Hugging Face\n",
        "modelo_emb_name = \"distilbert-base-uncased\"\n",
        "modelo_resp_name = \"facebook/blenderbot-400M-distill\"\n",
        "\n",
        "tokenizer_emb = AutoTokenizer.from_pretrained(modelo_emb_name)\n",
        "modelo_emb = AutoModel.from_pretrained(modelo_emb_name)\n",
        "\n",
        "tokenizer_resp = AutoTokenizer.from_pretrained(modelo_resp_name)\n",
        "modelo_resp = AutoModelForSeq2SeqLM.from_pretrained(modelo_resp_name)\n",
        "\n",
        "# Cargar el dataset del chatbot (intents.json)\n",
        "archivo_intents = \"intents.json\"\n",
        "try:\n",
        "    with open(archivo_intents, \"r\", encoding=\"utf-8\") as file:\n",
        "        intents = json.load(file)\n",
        "except FileNotFoundError:\n",
        "    intents = {\"intents\": []}\n",
        "\n",
        "# Cargar dataset de celulares\n",
        "archivo_celulares = \"celulares_limpios.json\"\n",
        "try:\n",
        "    with open(archivo_celulares, \"r\", encoding=\"utf-8\") as file:\n",
        "        celulares = json.load(file)\n",
        "except FileNotFoundError:\n",
        "    celulares = []\n",
        "\n",
        "# Memoria de la conversaciÃ³n (para recordar contexto)\n",
        "memoria_chat = []\n",
        "\n",
        "def obtener_embedding(frase):\n",
        "    tokens = tokenizer_emb(frase, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
        "    with torch.no_grad():\n",
        "        salida = modelo_emb(**tokens)\n",
        "    return salida.last_hidden_state[:, 0, :].numpy().flatten()\n",
        "\n",
        "patterns, labels = [], []\n",
        "\n",
        "for intent in intents[\"intents\"]:\n",
        "    if \"tag\" in intent and \"patterns\" in intent:\n",
        "        for pattern in intent[\"patterns\"]:\n",
        "            patterns.append(pattern)\n",
        "            labels.append(intent[\"tag\"])\n",
        "\n",
        "if patterns:\n",
        "    X = np.array([obtener_embedding(frase) for frase in patterns])\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(labels)\n",
        "\n",
        "    classifier = SVC(kernel=\"linear\", probability=True)\n",
        "    classifier.fit(X, y)\n",
        "else:\n",
        "    classifier = None\n",
        "\n",
        "def predecir_intencion(frase):\n",
        "    if classifier:\n",
        "        embedding = obtener_embedding(frase)\n",
        "        prediccion = classifier.predict([embedding])[0]\n",
        "        return label_encoder.inverse_transform([prediccion])[0]\n",
        "    return None\n",
        "\n",
        "def obtener_respuesta_json(intencion):\n",
        "    for intent in intents[\"intents\"]:\n",
        "        if intent[\"tag\"] == intencion:\n",
        "            return np.random.choice(intent[\"responses\"])\n",
        "    return None\n",
        "\n",
        "def generar_respuesta_transformer(frase):\n",
        "    tokens = tokenizer_resp(frase, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
        "    with torch.no_grad():\n",
        "        respuesta_ids = modelo_resp.generate(**tokens)\n",
        "    return tokenizer_resp.decode(respuesta_ids[0], skip_special_tokens=True)\n",
        "\n",
        "def respuesta_valida(respuesta):\n",
        "    palabras_invalidas = [\"no sÃ©\", \"no entiendo\", \"no puedo ayudar\", \"no tengo informaciÃ³n\"]\n",
        "    return not any(palabra in respuesta.lower() for palabra in palabras_invalidas)\n",
        "\n",
        "def guardar_aprendizaje(nueva_pregunta, nueva_respuesta):\n",
        "    global intents\n",
        "\n",
        "    if not respuesta_valida(nueva_respuesta):\n",
        "        return\n",
        "\n",
        "    intencion_predicha = predecir_intencion(nueva_pregunta)\n",
        "\n",
        "    if intencion_predicha:\n",
        "        for intent in intents[\"intents\"]:\n",
        "            if intent[\"tag\"] == intencion_predicha:\n",
        "                if nueva_pregunta not in intent[\"patterns\"]:\n",
        "                    intent[\"patterns\"].append(nueva_pregunta)\n",
        "                if nueva_respuesta not in intent[\"responses\"]:\n",
        "                    intent[\"responses\"].append(nueva_respuesta)\n",
        "                break\n",
        "    else:\n",
        "        nueva_categoria = f\"aprendizaje_{len(intents['intents'])+1}\"\n",
        "        intents[\"intents\"].append({\n",
        "            \"tag\": nueva_categoria,\n",
        "            \"patterns\": [nueva_pregunta],\n",
        "            \"responses\": [nueva_respuesta]\n",
        "        })\n",
        "\n",
        "    with open(archivo_intents, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(intents, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "def manejar_contexto(texto):\n",
        "    global memoria_chat\n",
        "    memoria_chat.append(texto)\n",
        "    if len(memoria_chat) > 3:\n",
        "        memoria_chat.pop(0)\n",
        "    return \" \".join(memoria_chat)\n",
        "\n",
        "def responder_chatbot(texto):\n",
        "    texto_con_contexto = manejar_contexto(texto)\n",
        "    intencion = predecir_intencion(texto_con_contexto)\n",
        "    respuesta = obtener_respuesta_json(intencion)\n",
        "\n",
        "    if respuesta:\n",
        "        return respuesta\n",
        "\n",
        "    for celular in celulares:\n",
        "        if any(palabra in texto.lower() for palabra in [celular[\"Company Name\"].lower(), celular[\"Model Name\"].lower()]):\n",
        "            return json.dumps(celular, indent=4)\n",
        "\n",
        "    respuesta_generada = generar_respuesta_transformer(texto_con_contexto)\n",
        "\n",
        "    if respuesta_valida(respuesta_generada):\n",
        "        guardar_aprendizaje(texto, respuesta_generada)\n",
        "\n",
        "    return respuesta_generada\n",
        "\n",
        "# FunciÃ³n para evaluar el chatbot\n",
        "def evaluar_chatbot(preguntas_evaluacion, respuestas_esperadas):\n",
        "    respuestas_predichas = [responder_chatbot(pregunta) for pregunta in preguntas_evaluacion]\n",
        "\n",
        "    # Convertir las etiquetas de texto a numÃ©ricas para la evaluaciÃ³n\n",
        "    y_true = [predecir_intencion(pregunta) for pregunta in preguntas_evaluacion]\n",
        "    y_pred = [predecir_intencion(respuesta) for respuesta in respuestas_predichas]\n",
        "\n",
        "    y_true_encoded = label_encoder.transform(y_true)\n",
        "    y_pred_encoded = label_encoder.transform(y_pred)\n",
        "\n",
        "    accuracy = accuracy_score(y_true_encoded, y_pred_encoded)\n",
        "    precision = precision_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "\n",
        "    print(f\"PrecisiÃ³n (Accuracy): {accuracy:.2f}\")\n",
        "    print(f\"PrecisiÃ³n (Precision): {precision:.2f}\")\n",
        "preguntas_evaluacion = [\n",
        "    # IntenciÃ³n \"saludo\"\n",
        "    \"Hola\",\n",
        "    \"Â¿CÃ³mo estÃ¡s?\",\n",
        "    \"Buenos dÃ­as\",\n",
        "    \"Â¡QuÃ© tal!\",\n",
        "    \"Hey\",\n",
        "    \"Â¿QuÃ© onda?\",\n",
        "    \"Dame saludos\",\n",
        "    \"Â¿Me saludas?\",\n",
        "\n",
        "    # IntenciÃ³n \"despedida\"\n",
        "    \"AdiÃ³s\",\n",
        "    \"Hasta luego\",\n",
        "    \"Nos vemos\",\n",
        "    \"Chao\",\n",
        "    \"Me voy\",\n",
        "    \"Bye\",\n",
        "    \"Hasta la vista\",\n",
        "    \"CuÃ­date\",\n",
        "    \"Debo irme\",\n",
        "    \"DespÃ­dete\",\n",
        "\n",
        "    # IntenciÃ³n \"agradecimientos\"\n",
        "    \"gracias\",\n",
        "    \"muchas gracias\",\n",
        "    \"mil gracias\",\n",
        "    \"muy amable\",\n",
        "    \"se lo agradezco\",\n",
        "    \"fue de ayuda\",\n",
        "    \"gracias por la ayuda\",\n",
        "    \"muy agradecido\",\n",
        "    \"gracias por tu tiempo\",\n",
        "    \"gracias por responder\",\n",
        "    \"Te agradezco mucho\",\n",
        "\n",
        "    # IntenciÃ³n \"celulares_para_juegos\"\n",
        "    \"jugar\",\n",
        "    \"gaming\",\n",
        "    \"potente para juegos\",\n",
        "    \"rendimiento en juegos\",\n",
        "    \"TelÃ©fonos gaming\",\n",
        "    \"Me gustan los juegos\",\n",
        "    \"para jugar\",\n",
        "    \"buena GPU\",\n",
        "    \"mejor celular gamer\",\n",
        "    \"Â¿QuÃ© celular es bueno para jugar?\",\n",
        "\n",
        "    # IntenciÃ³n \"cÃ¡mara_y_fotografÃ­a\"\n",
        "    \"buena cÃ¡mara\",\n",
        "    \"tomar fotos\",\n",
        "    \"cÃ¡mara de alta calidad\",\n",
        "    \"mejor cÃ¡mara\",\n",
        "    \"fotografÃ­a\",\n",
        "    \"fotos profesionales\",\n",
        "    \"buen zoom\",\n",
        "    \"cÃ¡mara nocturna\",\n",
        "    \"estabilizaciÃ³n Ã³ptica\",\n",
        "    \"cÃ¡mara frontal\",\n",
        "    \"Â¿QuÃ© celular tiene buena cÃ¡mara para fotos?\",\n",
        "\n",
        "    # IntenciÃ³n \"resistencia_y_durabilidad\"\n",
        "    \"resistente\",\n",
        "    \"no se rompa fÃ¡cil\",\n",
        "    \"aguante golpes\",\n",
        "    \"certificaciÃ³n IP68\",\n",
        "    \"resistente al agua\",\n",
        "    \"a prueba de polvo\",\n",
        "    \"todoterreno\",\n",
        "    \"reforzado\",\n",
        "    \"Gorilla Glass\",\n",
        "    \"Â¿QuÃ© celular es resistente al agua y golpes?\",\n",
        "\n",
        "    # IntenciÃ³n \"trabajo_y_productividad\"\n",
        "    \"trabajo\",\n",
        "    \"negocios\",\n",
        "    \"multitarea\",\n",
        "    \"S Pen\",\n",
        "    \"almacenamiento\",\n",
        "    \"rÃ¡pido\",\n",
        "    \"videollamadas\",\n",
        "    \"productividad\",\n",
        "    \"Microsoft Office\",\n",
        "    \"baterÃ­a\",\n",
        "    \"Â¿QuÃ© celular es bueno para trabajar?\",\n",
        "\n",
        "    # IntenciÃ³n \"software_y_actualizaciones\"\n",
        "    \"soporte de actualizaciones\",\n",
        "    \"soporte de software\",\n",
        "    \"seguridad actualizada\",\n",
        "    \"Android 15\",\n",
        "    \"Actualizacion\",\n",
        "    \"Â¿QuÃ© celular tiene la Ãºltima versiÃ³n de android?\",\n",
        "\n",
        "    # IntenciÃ³n \"celulares_por_marca\"\n",
        "    \"Samsung\",\n",
        "    \"Apple\",\n",
        "    \"Xiaomi\",\n",
        "    \"Motorola\",\n",
        "    \"Realme\",\n",
        "    \"Huawei\",\n",
        "    \"Google Pixel\",\n",
        "    \"OnePlus\",\n",
        "    \"Asus\",\n",
        "    \"Sony\",\n",
        "    \"Â¿QuÃ© celulares tiene Samsung?\",\n",
        "\n",
        "    # IntenciÃ³n \"pantalla_y_calidad\"\n",
        "    \"pantalla\",\n",
        "    \"AMOLED\",\n",
        "    \"Hercios\",\n",
        "    \"Hz\",\n",
        "    \"pulgadas\",\n",
        "    \"OLED\",\n",
        "    \"HDR10\",\n",
        "    \"resoluciÃ³n\",\n",
        "    \"Â¿QuÃ© celular tiene buena pantalla?\",\n",
        "\n",
        "    # IntenciÃ³n \"celulares_nuevos_y_antiguos\"\n",
        "    \"nuevo\",\n",
        "    \"este aÃ±o\",\n",
        "    \"reciente\",\n",
        "    \"Ãºltima generaciÃ³n\",\n",
        "    \"Â¿QuÃ© celulares nuevos hay?\"\n",
        "]\n",
        "\n",
        "respuestas_esperadas = [\n",
        "    # IntenciÃ³n \"saludo\"\n",
        "    \"saludo\",\n",
        "    \"saludo\",\n",
        "    \"saludo\",\n",
        "    \"saludo\",\n",
        "    \"saludo\",\n",
        "    \"saludo\",\n",
        "    \"saludo\",\n",
        "    \"saludo\",\n",
        "\n",
        "    # IntenciÃ³n \"despedida\"\n",
        "    \"despedida\",\n",
        "    \"despedida\",\n",
        "    \"despedida\",\n",
        "    \"despedida\",\n",
        "    \"despedida\",\n",
        "    \"despedida\",\n",
        "    \"despedida\",\n",
        "    \"despedida\",\n",
        "    \"despedida\",\n",
        "    \"despedida\",\n",
        "\n",
        "    # IntenciÃ³n \"agradecimientos\"\n",
        "    \"agradecimientos\",\n",
        "    \"agradecimientos\",\n",
        "    \"agradecimientos\",\n",
        "    \"agradecimientos\",\n",
        "    \"agradecimientos\",\n",
        "    \"agradecimientos\",\n",
        "    \"agradecimientos\",\n",
        "    \"agradecimientos\",\n",
        "    \"agradecimientos\",\n",
        "    \"agradecimientos\",\n",
        "    \"agradecimientos\",\n",
        "\n",
        "    # IntenciÃ³n \"celulares_para_juegos\"\n",
        "    \"celulares_para_juegos\",\n",
        "    \"celulares_para_juegos\",\n",
        "    \"celulares_para_juegos\",\n",
        "    \"celulares_para_juegos\",\n",
        "    \"celulares_para_juegos\",\n",
        "    \"celulares_para_juegos\",\n",
        "    \"celulares_para_juegos\",\n",
        "    \"celulares_para_juegos\",\n",
        "    \"celulares_para_juegos\",\n",
        "    \"celulares_para_juegos\",\n",
        "\n",
        "    # IntenciÃ³n \"cÃ¡mara_y_fotografÃ­a\"\n",
        "    \"cÃ¡mara_y_fotografÃ­a\",\n",
        "    \"cÃ¡mara_y_fotografÃ­a\",\n",
        "    \"cÃ¡mara_y_fotografÃ­a\",\n",
        "    \"cÃ¡mara_y_fotografÃ­a\",\n",
        "    \"cÃ¡mara_y_fotografÃ­a\",\n",
        "    \"cÃ¡mara_y_fotografÃ­a\",\n",
        "    \"cÃ¡mara_y_fotografÃ­a\",\n",
        "    \"cÃ¡mara_y_fotografÃ­a\",\n",
        "    \"cÃ¡mara_y_fotografÃ­a\",\n",
        "    \"cÃ¡mara_y_fotografÃ­a\",\n",
        "    \"cÃ¡mara_y_fotografÃ­a\",\n",
        "\n",
        "    # IntenciÃ³n \"resistencia_y_durabilidad\"\n",
        "    \"resistencia_y_durabilidad\",\n",
        "    \"resistencia_y_durabilidad\",\n",
        "    \"resistencia_y_durabilidad\",\n",
        "    \"resistencia_y_durabilidad\",\n",
        "    \"resistencia_y_durabilidad\",\n",
        "    \"resistencia_y_durabilidad\",\n",
        "    \"resistencia_y_durabilidad\",\n",
        "    \"resistencia_y_durabilidad\",\n",
        "    \"resistencia_y_durabilidad\",\n",
        "    \"resistencia_y_durabilidad\",\n",
        "\n",
        "    # IntenciÃ³n \"trabajo_y_productividad\"\n",
        "    \"trabajo_y_productividad\",\n",
        "    \"trabajo_y_productividad\",\n",
        "    \"trabajo_y_productividad\",\n",
        "    \"trabajo_y_productividad\",\n",
        "    \"trabajo_y_productividad\",\n",
        "    \"trabajo_y_productividad\",\n",
        "    \"trabajo_y_productividad\",\n",
        "    \"trabajo_y_productividad\",\n",
        "    \"trabajo_y_productividad\",\n",
        "    \"trabajo_y_productividad\",\n",
        "    \"trabajo_y_productividad\",\n",
        "\n",
        "    # IntenciÃ³n \"software_y_actualizaciones\"\n",
        "    \"software_y_actualizaciones\",\n",
        "    \"software_y_actualizaciones\",\n",
        "    \"software_y_actualizaciones\",\n",
        "    \"software_y_actualizaciones\",\n",
        "    \"software_y_actualizaciones\",\n",
        "    \"software_y_actualizaciones\",\n",
        "\n",
        "    # IntenciÃ³n \"celulares_por_marca\"\n",
        "    \"celulares_por_marca\",\n",
        "    \"celulares_por_marca\",\n",
        "    \"celulares_por_marca\",\n",
        "    \"celulares_por_marca\",\n",
        "    \"celulares_por_marca\",\n",
        "    \"celulares_por_marca\",\n",
        "    \"celulares_por_marca\",\n",
        "    \"celulares_por_marca\",\n",
        "    \"celulares_por_marca\",\n",
        "    \"celulares_por_marca\",\n",
        "    \"celulares_por_marca\",\n",
        "\n",
        "    # IntenciÃ³n \"pantalla_y_calidad\"\n",
        "    \"pantalla_y_calidad\",\n",
        "    \"pantalla_y_calidad\",\n",
        "    \"pantalla_y_calidad\",\n",
        "    \"pantalla_y_calidad\",\n",
        "    \"pantalla_y_calidad\",\n",
        "    \"pantalla_y_calidad\",\n",
        "    \"pantalla_y_calidad\",\n",
        "    \"pantalla_y_calidad\",\n",
        "    \"pantalla_y_calidad\",\n",
        "\n",
        "    # IntenciÃ³n \"celulares_nuevos_y_antiguos\"\n",
        "    \"celulares_nuevos_y_antiguos\",\n",
        "    \"celulares_nuevos_y_antiguos\",\n",
        "    \"celulares_nuevos_y_antiguos\",\n",
        "    \"celulares_nuevos_y_antiguos\",\n",
        "    \"celulares_nuevos_y_antiguos\"\n",
        "]\n",
        "evaluar_chatbot(preguntas_evaluacion, respuestas_esperadas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvERS1O-TMSz",
        "outputId": "c55a97ee-78d7-4283-9c81-5e6d5a0c025b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PrecisiÃ³n (Accuracy): 0.22\n",
            "PrecisiÃ³n (Precision): 0.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zEZPr8XAWXFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hyg1R0tEWW93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "inViWbnIY5sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ouksutKlY5fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agqxPGiaZ9XM",
        "outputId": "212d4009-a2f9-4403-e60c-1bd14f8547e4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TVhizw5bZlYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NeQnvRUfZlV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cHuaF_T2ZlTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PRUEBA 2.0 CON LOS INTENTS.JSON COMPLETOS"
      ],
      "metadata": {
        "id": "1PrQG8d5baRG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Slvhndt9ZkJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score  # MÃ©tricas de evaluaciÃ³n\n",
        "\n",
        "# Cargar modelos de Hugging Face\n",
        "modelo_emb_name = \"distilbert-base-uncased\"\n",
        "modelo_resp_name = \"facebook/blenderbot-400M-distill\"\n",
        "\n",
        "tokenizer_emb = AutoTokenizer.from_pretrained(modelo_emb_name)\n",
        "modelo_emb = AutoModel.from_pretrained(modelo_emb_name)\n",
        "\n",
        "tokenizer_resp = AutoTokenizer.from_pretrained(modelo_resp_name)\n",
        "modelo_resp = AutoModelForSeq2SeqLM.from_pretrained(modelo_resp_name)\n",
        "\n",
        "# Cargar el dataset del chatbot (intents.json)\n",
        "archivo_intents = \"intents.json\"\n",
        "try:\n",
        "    with open(archivo_intents, \"r\", encoding=\"utf-8\") as file:\n",
        "        intents = json.load(file)\n",
        "except FileNotFoundError:\n",
        "    intents = {\"intents\": []}\n",
        "\n",
        "# Cargar dataset de celulares\n",
        "archivo_celulares = \"celulares_limpios.json\"\n",
        "try:\n",
        "    with open(archivo_celulares, \"r\", encoding=\"utf-8\") as file:\n",
        "        celulares = json.load(file)\n",
        "except FileNotFoundError:\n",
        "    celulares = []\n",
        "\n",
        "# Memoria de la conversaciÃ³n (para recordar contexto)\n",
        "memoria_chat = []\n",
        "\n",
        "def obtener_embedding(frase):\n",
        "    tokens = tokenizer_emb(frase, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
        "    with torch.no_grad():\n",
        "        salida = modelo_emb(**tokens)\n",
        "    return salida.last_hidden_state[:, 0, :].numpy().flatten()\n",
        "\n",
        "patterns, labels = [], []\n",
        "\n",
        "for intent in intents[\"intents\"]:\n",
        "    if \"tag\" in intent and \"patterns\" in intent:\n",
        "        for pattern in intent[\"patterns\"]:\n",
        "            patterns.append(pattern)\n",
        "            labels.append(intent[\"tag\"])\n",
        "\n",
        "if patterns:\n",
        "    X = np.array([obtener_embedding(frase) for frase in patterns])\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(labels)\n",
        "\n",
        "    classifier = SVC(kernel=\"linear\", probability=True)\n",
        "    classifier.fit(X, y)\n",
        "else:\n",
        "    classifier = None\n",
        "\n",
        "def predecir_intencion(frase):\n",
        "    if classifier:\n",
        "        embedding = obtener_embedding(frase)\n",
        "        prediccion = classifier.predict([embedding])[0]\n",
        "        return label_encoder.inverse_transform([prediccion])[0]\n",
        "    return None\n",
        "\n",
        "def obtener_respuesta_json(intencion):\n",
        "    for intent in intents[\"intents\"]:\n",
        "        if intent[\"tag\"] == intencion:\n",
        "            return np.random.choice(intent[\"responses\"])\n",
        "    return None\n",
        "\n",
        "def generar_respuesta_transformer(frase):\n",
        "    tokens = tokenizer_resp(frase, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
        "    with torch.no_grad():\n",
        "        respuesta_ids = modelo_resp.generate(**tokens)\n",
        "    return tokenizer_resp.decode(respuesta_ids[0], skip_special_tokens=True)\n",
        "\n",
        "def respuesta_valida(respuesta):\n",
        "    palabras_invalidas = [\"no sÃ©\", \"no entiendo\", \"no puedo ayudar\", \"no tengo informaciÃ³n\"]\n",
        "    return not any(palabra in respuesta.lower() for palabra in palabras_invalidas)\n",
        "\n",
        "def guardar_aprendizaje(nueva_pregunta, nueva_respuesta):\n",
        "    global intents\n",
        "\n",
        "    if not respuesta_valida(nueva_respuesta):\n",
        "        return\n",
        "\n",
        "    intencion_predicha = predecir_intencion(nueva_pregunta)\n",
        "\n",
        "    if intencion_predicha:\n",
        "        for intent in intents[\"intents\"]:\n",
        "            if intent[\"tag\"] == intencion_predicha:\n",
        "                if nueva_pregunta not in intent[\"patterns\"]:\n",
        "                    intent[\"patterns\"].append(nueva_pregunta)\n",
        "                if nueva_respuesta not in intent[\"responses\"]:\n",
        "                    intent[\"responses\"].append(nueva_respuesta)\n",
        "                break\n",
        "    else:\n",
        "        nueva_categoria = f\"aprendizaje_{len(intents['intents'])+1}\"\n",
        "        intents[\"intents\"].append({\n",
        "            \"tag\": nueva_categoria,\n",
        "            \"patterns\": [nueva_pregunta],\n",
        "            \"responses\": [nueva_respuesta]\n",
        "        })\n",
        "\n",
        "    with open(archivo_intents, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(intents, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "def manejar_contexto(texto):\n",
        "    global memoria_chat\n",
        "    memoria_chat.append(texto)\n",
        "    if len(memoria_chat) > 3:\n",
        "        memoria_chat.pop(0)\n",
        "    return \" \".join(memoria_chat)\n",
        "\n",
        "def responder_chatbot(texto):\n",
        "    texto_con_contexto = manejar_contexto(texto)\n",
        "    intencion = predecir_intencion(texto_con_contexto)\n",
        "    respuesta = obtener_respuesta_json(intencion)\n",
        "\n",
        "    if respuesta:\n",
        "        return respuesta\n",
        "\n",
        "    for celular in celulares:\n",
        "        if any(palabra in texto.lower() for palabra in [celular[\"Company Name\"].lower(), celular[\"Model Name\"].lower()]):\n",
        "            return json.dumps(celular, indent=4)\n",
        "\n",
        "    respuesta_generada = generar_respuesta_transformer(texto_con_contexto)\n",
        "\n",
        "    if respuesta_valida(respuesta_generada):\n",
        "        guardar_aprendizaje(texto, respuesta_generada)\n",
        "\n",
        "    return respuesta_generada\n",
        "\n",
        "# FunciÃ³n para evaluar el chatbot\n",
        "def evaluar_chatbot(preguntas_evaluacion, respuestas_esperadas):\n",
        "    respuestas_predichas = [responder_chatbot(pregunta) for pregunta in preguntas_evaluacion]\n",
        "\n",
        "    # Convertir las etiquetas de texto a numÃ©ricas para la evaluaciÃ³n\n",
        "    y_true = [predecir_intencion(pregunta) for pregunta in preguntas_evaluacion]\n",
        "    y_pred = [predecir_intencion(respuesta) for respuesta in respuestas_predichas]\n",
        "\n",
        "    y_true_encoded = label_encoder.transform(y_true)\n",
        "    y_pred_encoded = label_encoder.transform(y_pred)\n",
        "\n",
        "    accuracy = accuracy_score(y_true_encoded, y_pred_encoded)\n",
        "    precision = precision_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score  # MÃ©tricas de evaluaciÃ³n\n",
        "\n",
        "# Cargar modelos de Hugging Face\n",
        "modelo_emb_name = \"distilbert-base-uncased\"\n",
        "modelo_resp_name = \"facebook/blenderbot-400M-distill\"\n",
        "\n",
        "tokenizer_emb = AutoTokenizer.from_pretrained(modelo_emb_name)\n",
        "modelo_emb = AutoModel.from_pretrained(modelo_emb_name)\n",
        "\n",
        "tokenizer_resp = AutoTokenizer.from_pretrained(modelo_resp_name)\n",
        "modelo_resp = AutoModelForSeq2SeqLM.from_pretrained(modelo_resp_name)\n",
        "\n",
        "# Cargar el dataset del chatbot (intents.json)\n",
        "archivo_intents = \"intents.json\"\n",
        "try:\n",
        "    with open(archivo_intents, \"r\", encoding=\"utf-8\") as file:\n",
        "        intents = json.load(file)\n",
        "except FileNotFoundError:\n",
        "    intents = {\"intents\": []}\n",
        "\n",
        "# Cargar dataset de celulares\n",
        "archivo_celulares = \"celulares_limpios.json\"\n",
        "try:\n",
        "    with open(archivo_celulares, \"r\", encoding=\"utf-8\") as file:\n",
        "        celulares = json.load(file)\n",
        "except FileNotFoundError:\n",
        "    celulares = []\n",
        "\n",
        "# Memoria de la conversaciÃ³n (para recordar contexto)\n",
        "memoria_chat = []\n",
        "\n",
        "def obtener_embedding(frase):\n",
        "    tokens = tokenizer_emb(frase, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
        "    with torch.no_grad():\n",
        "        salida = modelo_emb(**tokens)\n",
        "    return salida.last_hidden_state[:, 0, :].numpy().flatten()\n",
        "\n",
        "patterns, labels = [], []\n",
        "\n",
        "for intent in intents[\"intents\"]:\n",
        "    if \"tag\" in intent and \"patterns\" in intent:\n",
        "        for pattern in intent[\"patterns\"]:\n",
        "            patterns.append(pattern)\n",
        "            labels.append(intent[\"tag\"])\n",
        "\n",
        "if patterns:\n",
        "    X = np.array([obtener_embedding(frase) for frase in patterns])\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(labels)\n",
        "\n",
        "    classifier = SVC(kernel=\"linear\", probability=True)\n",
        "    classifier.fit(X, y)\n",
        "else:\n",
        "    classifier = None\n",
        "\n",
        "def predecir_intencion(frase):\n",
        "    if classifier:\n",
        "        embedding = obtener_embedding(frase)\n",
        "        prediccion = classifier.predict([embedding])[0]\n",
        "        return label_encoder.inverse_transform([prediccion])[0]\n",
        "    return None\n",
        "\n",
        "def obtener_respuesta_json(intencion):\n",
        "    for intent in intents[\"intents\"]:\n",
        "        if intent[\"tag\"] == intencion:\n",
        "            return np.random.choice(intent[\"responses\"])\n",
        "    return None\n",
        "\n",
        "def generar_respuesta_transformer(frase):\n",
        "    tokens = tokenizer_resp(frase, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
        "    with torch.no_grad():\n",
        "        respuesta_ids = modelo_resp.generate(**tokens)\n",
        "    return tokenizer_resp.decode(respuesta_ids[0], skip_special_tokens=True)\n",
        "\n",
        "def respuesta_valida(respuesta):\n",
        "    palabras_invalidas = [\"no sÃ©\", \"no entiendo\", \"no puedo ayudar\", \"no tengo informaciÃ³n\"]\n",
        "    return not any(palabra in respuesta.lower() for palabra in palabras_invalidas)\n",
        "\n",
        "def guardar_aprendizaje(nueva_pregunta, nueva_respuesta):\n",
        "    global intents\n",
        "\n",
        "    if not respuesta_valida(nueva_respuesta):\n",
        "        return\n",
        "\n",
        "    intencion_predicha = predecir_intencion(nueva_pregunta)\n",
        "\n",
        "    if intencion_predicha:\n",
        "        for intent in intents[\"intents\"]:\n",
        "            if intent[\"tag\"] == intencion_predicha:\n",
        "                if nueva_pregunta not in intent[\"patterns\"]:\n",
        "                    intent[\"patterns\"].append(nueva_pregunta)\n",
        "                if nueva_respuesta not in intent[\"responses\"]:\n",
        "                    intent[\"responses\"].append(nueva_respuesta)\n",
        "                break\n",
        "    else:\n",
        "        nueva_categoria = f\"aprendizaje_{len(intents['intents'])+1}\"\n",
        "        intents[\"intents\"].append({\n",
        "            \"tag\": nueva_categoria,\n",
        "            \"patterns\": [nueva_pregunta],\n",
        "            \"responses\": [nueva_respuesta]\n",
        "        })\n",
        "\n",
        "    with open(archivo_intents, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(intents, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "def manejar_contexto(texto):\n",
        "    global memoria_chat\n",
        "    memoria_chat.append(texto)\n",
        "    if len(memoria_chat) > 3:\n",
        "        memoria_chat.pop(0)\n",
        "    return \" \".join(memoria_chat)\n",
        "\n",
        "def responder_chatbot(texto):\n",
        "    texto_con_contexto = manejar_contexto(texto)\n",
        "    intencion = predecir_intencion(texto_con_contexto)\n",
        "    respuesta = obtener_respuesta_json(intencion)\n",
        "\n",
        "    if respuesta:\n",
        "        return respuesta\n",
        "\n",
        "    for celular in celulares:\n",
        "        if any(palabra in texto.lower() for palabra in [celular[\"Company Name\"].lower(), celular[\"Model Name\"].lower()]):\n",
        "            return json.dumps(celular, indent=4)\n",
        "\n",
        "    respuesta_generada = generar_respuesta_transformer(texto_con_contexto)\n",
        "\n",
        "    if respuesta_valida(respuesta_generada):\n",
        "        guardar_aprendizaje(texto, respuesta_generada)\n",
        "\n",
        "    return respuesta_generada\n",
        "\n",
        "# FunciÃ³n para evaluar el chatbot\n",
        "def evaluar_chatbot(preguntas_evaluacion, respuestas_esperadas):\n",
        "    respuestas_predichas = [responder_chatbot(pregunta) for pregunta in preguntas_evaluacion]\n",
        "\n",
        "    # Convertir las etiquetas de texto a numÃ©ricas para la evaluaciÃ³n\n",
        "    y_true = [predecir_intencion(pregunta) for pregunta in preguntas_evaluacion]\n",
        "    y_pred = [predecir_intencion(respuesta) for respuesta in respuestas_predichas if respuesta is not None]\n",
        "\n",
        "    if y_true and y_pred:\n",
        "        y_true_encoded = label_encoder.transform(y_true)\n",
        "        y_pred_encoded = label_encoder.transform(y_pred)\n",
        "\n",
        "        accuracy = accuracy_score(y_true_encoded, y_pred_encoded)\n",
        "        precision = precision_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "        recall = recall_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "        f1 = f1_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "\n",
        "        print(f\"PrecisiÃ³n (Accuracy): {accuracy:.2f}\")\n",
        "        print(f\"PrecisiÃ³n (Precision): {precision:.2f}\")\n",
        "    else:\n",
        "        print(\"No se pudieron generar predicciones para calcular las mÃ©tricas.\")\n",
        "\n",
        "\n",
        "preguntas_evaluacion = [\n",
        "\n",
        "    # IntenciÃ³n \"saludo\"\n",
        "    \"Hola\",\n",
        "    \"Â¿CÃ³mo estÃ¡s?\",\n",
        "    \"Buenos dÃ­as\",\n",
        "    \"Â¡QuÃ© tal!\",\n",
        "    \"Hey\",\n",
        "    \"Â¿QuÃ© onda?\",\n",
        "    \"Dame saludos\",\n",
        "    \"Â¿Me saludas?\",\n",
        "\n",
        "    # IntenciÃ³n \"despedida\"\n",
        "    \"AdiÃ³s\",\n",
        "    \"Hasta luego\",\n",
        "    \"Nos vemos\",\n",
        "    \"Chao\",\n",
        "    \"Me voy\",\n",
        "    \"Bye\",\n",
        "    \"Hasta la vista\",\n",
        "    \"CuÃ­date\",\n",
        "    \"Debo irme\",\n",
        "    \"DespÃ­dete\",\n",
        "\n",
        "    # IntenciÃ³n \"agradecimientos\"\n",
        "    \"gracias\",\n",
        "    \"muchas gracias\",\n",
        "    \"mil gracias\",\n",
        "    \"muy amable\",\n",
        "    \"se lo agradezco\",\n",
        "    \"fue de ayuda\",\n",
        "    \"gracias por la ayuda\",\n",
        "    \"muy agradecido\",\n",
        "    \"gracias por tu tiempo\",\n",
        "    \"gracias por responder\",\n",
        "    \"Te agradezco mucho\",\n",
        "\n",
        "    # IntenciÃ³n \"celulares_para_juegos\"\n",
        "    \"jugar\",\n",
        "    \"gaming\",\n",
        "    \"potente para juegos\",\n",
        "    \"rendimiento en juegos\",\n",
        "    \"TelÃ©fonos gaming\",\n",
        "    \"Me gustan los juegos\",\n",
        "    \"para jugar\",\n",
        "    \"buena GPU\",\n",
        "    \"mejor celular gamer\",\n",
        "    \"Â¿QuÃ© celular es bueno para jugar?\",\n",
        "\n",
        "    # IntenciÃ³n \"cÃ¡mara_y_fotografia\"\n",
        "    \"buena cÃ¡mara\",\n",
        "    \"tomar fotos\",\n",
        "    \"cÃ¡mara de alta calidad\",\n",
        "    \"mejor cÃ¡mara\",\n",
        "    \"fotografÃ­a\",\n",
        "    \"fotos profesionales\",\n",
        "    \"buen zoom\",\n",
        "    \"cÃ¡mara nocturna\",\n",
        "    \"estabilizaciÃ³n Ã³ptica\",\n",
        "    \"cÃ¡mara frontal\",\n",
        "    \"Â¿QuÃ© celular tiene buena cÃ¡mara para fotos?\",\n",
        "\n",
        "    # IntenciÃ³n \"resistencia_y_durabilidad\"\n",
        "    \"resistente\",\n",
        "    \"no se rompa\",\n",
        "    \"Â¿CÃ³mo estÃ¡s?\",\n",
        "    \"Buenos dÃ­as\",\n",
        "    \"Â¡QuÃ© tal!\",\n",
        "    \"Hey\",\n",
        "    \"Â¿QuÃ© onda?\",\n",
        "    \"Dame saludos\",\n",
        "    \"Â¿Me saludas?\",\n",
        "\n",
        "    # IntenciÃ³n \"despedida\"\n",
        "    \"AdiÃ³s\",\n",
        "    \"Hasta luego\",\n",
        "    \"Nos vemos\",\n",
        "    \"Chao\",\n",
        "    \"Me voy\",\n",
        "    \"Bye\",\n",
        "    \"Hasta la vista\",\n",
        "    \"CuÃ­date\",\n",
        "    \"Debo irme\",\n",
        "    \"DespÃ­dete\",\n",
        "\n",
        "    # IntenciÃ³n \"agradecimientos\"\n",
        "    \"gracias\",\n",
        "    \"muchas gracias\",\n",
        "    \"mil gracias\",\n",
        "    \"muy amable\",\n",
        "    \"se lo agradezco\",\n",
        "    \"fue de ayuda\",\n",
        "    \"gracias por la ayuda\",\n",
        "    \"muy agradecido\",\n",
        "    \"gracias por tu tiempo\",\n",
        "    \"gracias por responder\",\n",
        "    \"Te agradezco mucho\",\n",
        "\n",
        "    # IntenciÃ³n \"celulares_para_juegos\"\n",
        "    \"jugar\",\n",
        "    \"gaming\",\n",
        "    \"potente para juegos\",\n",
        "    \"rendimiento en juegos\",\n",
        "    \"TelÃ©fonos gaming\",\n",
        "    \"Me gustan los juegos\",\n",
        "    \"para jugar\",\n",
        "    \"buena GPU\",\n",
        "    \"mejor celular gamer\",\n",
        "    \"Â¿QuÃ© celular es bueno para jugar?\",\n",
        "\n",
        "    # IntenciÃ³n \"cÃ¡mara_y_fotografÃ­a\"\n",
        "    \"buena cÃ¡mara\",\n",
        "    \"tomar fotos\",\n",
        "    \"cÃ¡mara de alta calidad\",\n",
        "    \"mejor cÃ¡mara\",\n",
        "    \"fotografÃ­a\",\n",
        "    \"fotos profesionales\",\n",
        "    \"buen zoom\",\n",
        "    \"cÃ¡mara nocturna\",\n",
        "    \"estabilizaciÃ³n Ã³ptica\",\n",
        "    \"cÃ¡mara frontal\",\n",
        "    \"Â¿QuÃ© celular tiene buena cÃ¡mara para fotos?\",\n",
        "\n",
        "    # IntenciÃ³n \"resistencia_y_durabilidad\"\n",
        "    \"resistente\",\n",
        "    \"no se rompa fÃ¡cil\",\n",
        "    \"aguante golpes\",\n",
        "    \"certificaciÃ³n IP68\",\n",
        "    \"resistente al agua\",\n",
        "    \"a prueba de polvo\",\n",
        "    \"todoterreno\",\n",
        "    \"reforzado\",\n",
        "    \"Gorilla Glass\",\n",
        "    \"Â¿QuÃ© celular es resistente al agua y golpes?\",\n",
        "\n",
        "    # IntenciÃ³n \"trabajo_y_productividad\"\n",
        "    \"trabajo\",\n",
        "    \"negocios\",\n",
        "    \"multitarea\",\n",
        "    \"S Pen\",\n",
        "    \"almacenamiento\",\n",
        "    \"rÃ¡pido\",\n",
        "    \"videollamadas\",\n",
        "    \"productividad\",\n",
        "    \"Microsoft Office\",\n",
        "    \"baterÃ­a\",\n",
        "    \"Â¿QuÃ© celular es bueno para trabajar?\",\n",
        "\n",
        "    # IntenciÃ³n \"software_y_actualizaciones\"\n",
        "    \"soporte de actualizaciones\",\n",
        "    \"soporte de software\",\n",
        "    \"seguridad actualizada\",\n",
        "    \"Android 15\",\n",
        "    \"Actualizacion\",\n",
        "    \"Â¿QuÃ© celular tiene la Ãºltima versiÃ³n de android?\",\n",
        "\n",
        "    # IntenciÃ³n \"celulares_por_marca\"\n",
        "    \"Samsung\",\n",
        "    \"Apple\",\n",
        "    \"Xiaomi\",\n",
        "    \"Motorola\",\n",
        "    \"Realme\",\n",
        "    \"Huawei\",\n",
        "    \"Google Pixel\",\n",
        "    \"OnePlus\",\n",
        "    \"Asus\",\n",
        "    \"Sony\",\n",
        "    \"Â¿QuÃ© celulares tiene Samsung?\",\n",
        "\n",
        "    # IntenciÃ³n \"pantalla_y_calidad\"\n",
        "    \"pantalla\",\n",
        "    \"AMOLED\",\n",
        "    \"Hercios\",\n",
        "    \"Hz\",\n",
        "    \"pulgadas\",\n",
        "    \"OLED\",\n",
        "    \"HDR10\",\n",
        "    \"resoluciÃ³n\",\n",
        "    \"Â¿QuÃ© celular tiene buena pantalla?\",\n",
        "\n",
        "    # IntenciÃ³n \"celulares_nuevos_y_antiguos\"\n",
        "    \"nuevo\",\n",
        "    \"este aÃ±o\",\n",
        "    \"reciente\",\n",
        "    \"Ãºltima generaciÃ³n\",\n",
        "    \"Â¿QuÃ© celulares nuevos hay?\",\n",
        "   ]\n",
        "\n",
        "\n",
        "# Memoria de la conversaciÃ³n (para recordar contexto)\n",
        "memoria_chat = []\n",
        "\n",
        "def obtener_embedding(frase):\n",
        "    tokens = tokenizer_emb(frase, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
        "    with torch.no_grad():\n",
        "        salida = modelo_emb(**tokens)\n",
        "    return salida.last_hidden_state[:, 0, :].numpy().flatten()\n",
        "\n",
        "patterns, labels = [], []\n",
        "\n",
        "for intent in intents[\"intents\"]:\n",
        "    if \"tag\" in intent and \"patterns\" in intent:\n",
        "        for pattern in intent[\"patterns\"]:\n",
        "            patterns.append(pattern)\n",
        "            labels.append(intent[\"tag\"])\n",
        "\n",
        "if patterns:\n",
        "    X = np.array([obtener_embedding(frase) for frase in patterns])\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(labels)\n",
        "\n",
        "    classifier = SVC(kernel=\"linear\", probability=True)\n",
        "    classifier.fit(X, y)\n",
        "else:\n",
        "    classifier = None\n",
        "\n",
        "def predecir_intencion(frase):\n",
        "    if classifier:\n",
        "        embedding = obtener_embedding(frase)\n",
        "        prediccion = classifier.predict([embedding])[0]\n",
        "        return label_encoder.inverse_transform([prediccion])[0]\n",
        "    return None\n",
        "\n",
        "def obtener_respuesta_json(intencion):\n",
        "    for intent in intents[\"intents\"]:\n",
        "        if intent[\"tag\"] == intencion:\n",
        "            return np.random.choice(intent[\"responses\"])\n",
        "    return None\n",
        "\n",
        "def generar_respuesta_transformer(frase):\n",
        "    tokens = tokenizer_resp(frase, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
        "    with torch.no_grad():\n",
        "        respuesta_ids = modelo_resp.generate(**tokens)\n",
        "    return tokenizer_resp.decode(respuesta_ids[0], skip_special_tokens=True)\n",
        "\n",
        "def respuesta_valida(respuesta):\n",
        "    palabras_invalidas = [\"no sÃ©\", \"no entiendo\", \"no puedo ayudar\", \"no tengo informaciÃ³n\"]\n",
        "    return not any(palabra in respuesta.lower() for palabra in palabras_invalidas)\n",
        "\n",
        "def guardar_aprendizaje(nueva_pregunta, nueva_respuesta):\n",
        "    global intents\n",
        "\n",
        "    if not respuesta_valida(nueva_respuesta):\n",
        "        return\n",
        "\n",
        "    intencion_predicha = predecir_intencion(nueva_pregunta)\n",
        "\n",
        "    if intencion_predicha:\n",
        "        for intent in intents[\"intents\"]:\n",
        "            if intent[\"tag\"] == intencion_predicha:\n",
        "                if nueva_pregunta not in intent[\"patterns\"]:\n",
        "                    intent[\"patterns\"].append(nueva_pregunta)\n",
        "                if nueva_respuesta not in intent[\"responses\"]:\n",
        "                    intent[\"responses\"].append(nueva_respuesta)\n",
        "                break\n",
        "    else:\n",
        "        nueva_categoria = f\"aprendizaje_{len(intents['intents'])+1}\"\n",
        "        intents[\"intents\"].append({\n",
        "            \"tag\": nueva_categoria,\n",
        "            \"patterns\": [nueva_pregunta],\n",
        "            \"responses\": [nueva_respuesta]\n",
        "        })\n",
        "\n",
        "    with open(archivo_intents, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(intents, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "def manejar_contexto(texto):\n",
        "    global memoria_chat\n",
        "    memoria_chat.append(texto)\n",
        "    if len(memoria_chat) > 3:\n",
        "        memoria_chat.pop(0)\n",
        "    return \" \".join(memoria_chat)\n",
        "\n",
        "def responder_chatbot(texto):\n",
        "    texto_con_contexto = manejar_contexto(texto)\n",
        "    intencion = predecir_intencion(texto_con_contexto)\n",
        "    respuesta = obtener_respuesta_json(intencion)\n",
        "\n",
        "    if respuesta:\n",
        "        return respuesta\n",
        "\n",
        "    for celular in celulares:\n",
        "        if any(palabra in texto.lower() for palabra in [celular[\"Company Name\"].lower(), celular[\"Model Name\"].lower()]):\n",
        "            return json.dumps(celular, indent=4)\n",
        "\n",
        "    respuesta_generada = generar_respuesta_transformer(texto_con_contexto)\n",
        "\n",
        "    if respuesta_valida(respuesta_generada):\n",
        "        guardar_aprendizaje(texto, respuesta_generada)\n",
        "\n",
        "    return respuesta_generada\n",
        "\n",
        "# FunciÃ³n para evaluar el chatbot\n",
        "def evaluar_chatbot(preguntas_evaluacion, respuestas_esperadas):\n",
        "    respuestas_predichas = [responder_chatbot(pregunta) for pregunta in preguntas_evaluacion]\n",
        "\n",
        "    # Convertir las etiquetas de texto a numÃ©ricas para la evaluaciÃ³n\n",
        "    y_true = [predecir_intencion(pregunta) for pregunta in preguntas_evaluacion]\n",
        "    y_pred = [predecir_intencion(respuesta) for respuesta in respuestas_predichas if respuesta is not None]\n",
        "\n",
        "    if y_true and y_pred:\n",
        "        y_true_encoded = label_encoder.transform(y_true)\n",
        "        y_pred_encoded = label_encoder.transform(y_pred)\n",
        "\n",
        "        accuracy = accuracy_score(y_true_encoded, y_pred_encoded)\n",
        "        precision = precision_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "        recall = recall_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "        f1 = f1_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "\n",
        "        print(f\"PrecisiÃ³n (Accuracy): {accuracy:.2f}\")\n",
        "        print(f\"PrecisiÃ³n (Precision): {precision:.2f}\")\n",
        "    else:\n",
        "        print(\"No se pudieron generar predicciones para calcular las mÃ©tricas.\")\n",
        "\n",
        "\n",
        "preguntas_evaluacion = [\n",
        "    # IntenciÃ³n \"saludo\"\n",
        "    \"Hola\",\n",
        "    \"Â¿CÃ³mo estÃ¡s?\",\n",
        "    \"Buenos dÃ­as\",\n",
        "    \"Â¡QuÃ© tal!\",\n",
        "    \"Hey\",\n",
        "    \"Â¿QuÃ© onda?\",\n",
        "    \"Dame saludos\",\n",
        "    \"Â¿Me saludas?\",\n",
        "\n",
        "    # IntenciÃ³n \"despedida\"\n",
        "    \"AdiÃ³s\",\n",
        "    \"Hasta luego\",\n",
        "    \"Nos vemos\",\n",
        "    \"Chao\",\n",
        "    \"Me voy\",\n",
        "    \"Bye\",\n",
        "    \"Hasta la vista\",\n",
        "    \"CuÃ­date\",\n",
        "    \"Debo irme\",\n",
        "    \"DespÃ­dete\",\n",
        "\n",
        "    # IntenciÃ³n \"agradecimientos\"\n",
        "    \"gracias\",\n",
        "    \"muchas gracias\",\n",
        "    \"mil gracias\",\n",
        "    \"muy amable\",\n",
        "    \"se lo agradezco\",\n",
        "    \"fue de ayuda\",\n",
        "    \"gracias por la ayuda\",\n",
        "    \"muy agradecido\",\n",
        "    \"gracias por tu tiempo\",\n",
        "    \"gracias por responder\",\n",
        "    \"Te agradezco mucho\",\n",
        "\n",
        "    # IntenciÃ³n \"celulares_para_juegos\"\n",
        "    \"jugar\",\n",
        "    \"gaming\",\n",
        "    \"potente para juegos\",\n",
        "    \"rendimiento en juegos\",\n",
        "    \"TelÃ©fonos gaming\",\n",
        "    \"Me gustan los juegos\",\n",
        "    \"para jugar\",\n",
        "    \"buena GPU\",\n",
        "    \"mejor celular gamer\",\n",
        "    \"Â¿QuÃ© celular es bueno para jugar?\",\n",
        "\n",
        "    # IntenciÃ³n \"cÃ¡mara_y_fotografia\"\n",
        "    \"buena cÃ¡mara\",\n",
        "    \"tomar fotos\",\n",
        "    \"cÃ¡mara de alta calidad\",\n",
        "    \"mejor cÃ¡mara\",\n",
        "    \"fotografÃ­a\",\n",
        "    \"fotos profesionales\",\n",
        "    \"buen zoom\",\n",
        "    \"cÃ¡mara nocturna\",\n",
        "    \"estabilizaciÃ³n Ã³ptica\",\n",
        "    \"cÃ¡mara frontal\",\n",
        "    \"Â¿QuÃ© celular tiene buena cÃ¡mara para fotos?\",\n",
        "\n",
        "    # IntenciÃ³n \"resistencia_y_durabilidad\"\n",
        "    \"resistente\",\n",
        "    \"no se rompa\",\n",
        "    \"Â¡Hola! Â¿En quÃ© puedo ayudarte hoy?\",\n",
        "    \"Â¡Saludos! Â¿QuÃ© necesitas?\",\n",
        "    \"Â¡Hey! Â¿CÃ³mo estÃ¡s?\",\n",
        "    \"Â¡QuÃ© gusto verte!\",\n",
        "\n",
        "\n",
        "    # IntenciÃ³n \"despedida\"\n",
        "    \"Â¡Hasta luego! Que tengas un buen dÃ­a.\",\n",
        "    \"Â¡AdiÃ³s! Â¡Vuelve pronto!\",\n",
        "    \"Â¡Nos vemos! No dudes en preguntar cuando lo necesites.\",\n",
        "    \"Â¡CuÃ­date!\",\n",
        "    \"Bye, hasta la prÃ³xima.\",\n",
        "\n",
        "    # IntenciÃ³n \"agradecimientos\"\n",
        "    \"De nada, estoy aquÃ­ para ayudar.\",\n",
        "    \"Feliz por ayudar.\",\n",
        "    \"Gracias a ti por preguntar.\",\n",
        "    \"Â¡Siempre a la orden!\",\n",
        "    \"Fue un placer ayudarte.\",\n",
        "\n",
        "    # IntenciÃ³n \"celulares_para_juegos\"\n",
        "    \"Para gaming, te recomiendo un celular con un buen procesador y al menos 8GB de RAM.\",\n",
        "    \"Los telÃ©fonos con Snapdragon 8 Gen 2 y buena tasa de refresco son ideales para juegos.\",\n",
        "    \"Busca un celular con una GPU potente y refrigeraciÃ³n eficiente.\",\n",
        "    \"Algunos celulares gaming incluyen botones fÃ­sicos y triggers.\",\n",
        "    \"Â¿Tienes un presupuesto en mente? Puedo recomendarte algo segÃºn tu rango de precio.\",\n",
        "    # IntenciÃ³n \"cÃ¡mara_y_fotografÃ­a\"\n",
        "    \"Para fotografÃ­a, te sugiero un celular con al menos 50MP en la cÃ¡mara principal y buen procesamiento de imagen.\",\n",
        "    \"Los celulares de gama alta suelen tener mejores cÃ¡maras, pero hay opciones mÃ¡s accesibles con buenas prestaciones.\",\n",
        "    \"Busca un celular con estabilizaciÃ³n Ã³ptica para mejores fotos en movimiento.\",\n",
        "    \"Algunos modelos cuentan con teleobjetivo para capturas a larga distancia.\",\n",
        "    \"Â¿Prefieres un celular con cÃ¡mara profesional o algo mÃ¡s equilibrado?\",\n",
        "\n",
        "    # IntenciÃ³n \"resistencia_y_durabilidad\"\n",
        "    \"Si buscas un celular resistente, te recomiendo modelos con certificaciÃ³n IP68 o con protecciÃ³n militar.\",\n",
        "                \"Algunos celulares como los CAT o Samsung XCover estÃ¡n diseÃ±ados para resistir golpes y polvo.\",\n",
        "                \"Los celulares con Gorilla Glass suelen tener pantallas mÃ¡s resistentes.\",\n",
        "                \"Si trabajas en ambientes exigentes, te sugiero un smartphone todoterreno.\",\n",
        "    # IntenciÃ³n \"trabajo_y_productividad\"\n",
        "    \"Si buscas un celular para trabajo, te sugiero modelos con buena baterÃ­a y almacenamiento amplio.\",\n",
        "                \"Algunos modelos premium incluyen funciones especÃ­ficas para productividad como Samsung Dex o Apple Continuity.\",\n",
        "                \"Si necesitas tomar notas, te recomiendo un celular con lÃ¡piz Ã³ptico como la serie Galaxy Note o S Ultra.\",\n",
        "                \"Â¿Buscas algo potente o mÃ¡s enfocado en baterÃ­a y conectividad?\",\n",
        "\n",
        "    # IntenciÃ³n \"software_y_actualizaciones\"\n",
        "    \"Si buscas un celular con actualizaciones garantizadas, los Google Pixel y Samsung tienen buen soporte.\",\n",
        "                \"Apple ofrece soporte de software por mÃ¡s aÃ±os que la mayorÃ­a de marcas de Android.\",\n",
        "                \"Si te preocupa la seguridad, busca celulares con parches de seguridad mensuales.\",\n",
        "                \"Los celulares con Android puro suelen recibir actualizaciones mÃ¡s rÃ¡pido que los personalizados.\",\n",
        "\n",
        "    # IntenciÃ³n \"celulares_por_marca\"\n",
        "    \"Claro, aquÃ­ tienes modelos de la marca que buscas.\",\n",
        "                \"Estos son algunos de los mejores celulares de esa marca.\",\n",
        "                \"DÃ©jame filtrar los modelos disponibles de esa marca.\",\n",
        "                \"Los celulares de esta marca tienen diferentes opciones, Â¿buscas algo en especÃ­fico?\",\n",
        "                \"Puedo mostrarte los Ãºltimos lanzamientos o modelos populares de esa marca.\",\n",
        "\n",
        "    # IntenciÃ³n \"pantalla_y_calidad\"\n",
        "    \"Si buscas una pantalla grande, te recomendarÃ­a un modelo con mÃ¡s de 6.5 pulgadas.\",\n",
        "                \"Las pantallas AMOLED ofrecen mejor contraste y colores mÃ¡s vivos.\",\n",
        "                \"Los celulares con 120Hz ofrecen una experiencia mÃ¡s fluida al navegar y jugar.\",\n",
        "                \"Si quieres la mejor calidad de pantalla, busca modelos con HDR10 o Dolby Vision.\",\n",
        "                \"Â¿Te interesa mÃ¡s la calidad de imagen o el tamaÃ±o de la pantalla?\",\n",
        "\n",
        "    # IntenciÃ³n \"celulares_nuevos_y_antiguos\"\n",
        "    \"AquÃ­ tienes una lista de los celulares mÃ¡s recientes.\",\n",
        "                \"Estos son algunos modelos lanzados en los Ãºltimos meses.\",\n",
        "                \"Si buscas lo Ãºltimo en tecnologÃ­a, estos celulares pueden interesarte.\",\n",
        "                \"Â¿Te gustarÃ­a un modelo de gama alta o prefieres algo mÃ¡s asequible?\",\n",
        "                \"DÃ©jame buscar los modelos mÃ¡s recientes en nuestra base de datos.\",\n",
        " ]\n",
        "evaluar_chatbot(preguntas_evaluacion, respuestas_esperadas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBxsDoTOZlQL",
        "outputId": "ba784c5c-f542-47c3-cb30-5d4006809c52"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PrecisiÃ³n (Accuracy): 0.56\n",
            "PrecisiÃ³n (Precision): 0.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OSWNfZ9yhWkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2LHhu-NEhWcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k5SLZi4HhWUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "70IHlQzuhWM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BOT3.0 con error en las respuestas (supongo que es debido a que no logra reconocer el .json)\n"
      ],
      "metadata": {
        "id": "NvYqiXjVhXOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "IntentosXEficiencia.json ( es el documento generado)"
      ],
      "metadata": {
        "id": "pTHdbkSvlRuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score  # MÃ©tricas de evaluaciÃ³n\n",
        "\n",
        "# Cargar modelos de Hugging Face\n",
        "modelo_emb_name = \"distilbert-base-uncased\"\n",
        "modelo_resp_name = \"facebook/blenderbot-400M-distill\"\n",
        "\n",
        "tokenizer_emb = AutoTokenizer.from_pretrained(modelo_emb_name)\n",
        "modelo_emb = AutoModel.from_pretrained(modelo_emb_name)\n",
        "\n",
        "tokenizer_resp = AutoTokenizer.from_pretrained(modelo_resp_name)\n",
        "modelo_resp = AutoModelForSeq2SeqLM.from_pretrained(modelo_resp_name)\n",
        "\n",
        "# Cargar el dataset del chatbot (intents.json)\n",
        "archivo_intents = \"IntentosXEficiencia.json\"\n",
        "try:\n",
        "    with open(archivo_intents, \"r\", encoding=\"utf-8\") as file:\n",
        "        intents = json.load(file)\n",
        "except FileNotFoundError:\n",
        "    intents = {\"intents\": []}\n",
        "\n",
        "# Cargar dataset de celulares\n",
        "archivo_celulares = \"celulares_limpios.json\"\n",
        "try:\n",
        "    with open(archivo_celulares, \"r\", encoding=\"utf-8\") as file:\n",
        "        celulares = json.load(file)\n",
        "except FileNotFoundError:\n",
        "    celulares = []\n",
        "\n",
        "# Memoria de la conversaciÃ³n (para recordar contexto)\n",
        "memoria_chat = []\n",
        "\n",
        "def obtener_embedding(frase):\n",
        "    tokens = tokenizer_emb(frase, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
        "    with torch.no_grad():\n",
        "        salida = modelo_emb(**tokens)\n",
        "    return salida.last_hidden_state[:, 0, :].numpy().flatten()\n",
        "\n",
        "patterns, labels = [], []\n",
        "\n",
        "for intent in intents[\"intents\"]:\n",
        "    if \"tag\" in intent and \"patterns\" in intent:\n",
        "        for pattern in intent[\"patterns\"]:\n",
        "            patterns.append(pattern)\n",
        "            labels.append(intent[\"tag\"])\n",
        "\n",
        "if patterns:\n",
        "    X = np.array([obtener_embedding(frase) for frase in patterns])\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(labels)\n",
        "\n",
        "    classifier = SVC(kernel=\"linear\", probability=True)\n",
        "    classifier.fit(X, y)\n",
        "else:\n",
        "    classifier = None\n",
        "\n",
        "def predecir_intencion(frase):\n",
        "    if classifier:\n",
        "        embedding = obtener_embedding(frase)\n",
        "        prediccion = classifier.predict([embedding])[0]\n",
        "        return label_encoder.inverse_transform([prediccion])[0]\n",
        "    return None\n",
        "\n",
        "def obtener_respuesta_json(intencion):\n",
        "    for intent in intents[\"intents\"]:\n",
        "        if intent[\"tag\"] == intencion:\n",
        "            return np.random.choice(intent[\"responses\"])\n",
        "    return None\n",
        "\n",
        "def generar_respuesta_transformer(frase):\n",
        "    tokens = tokenizer_resp(frase, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
        "    with torch.no_grad():\n",
        "        respuesta_ids = modelo_resp.generate(**tokens)\n",
        "    return tokenizer_resp.decode(respuesta_ids[0], skip_special_tokens=True)\n",
        "\n",
        "def respuesta_valida(respuesta):\n",
        "    palabras_invalidas = [\"no sÃ©\", \"no entiendo\", \"no puedo ayudar\", \"no tengo informaciÃ³n\"]\n",
        "    return not any(palabra in respuesta.lower() for palabra in palabras_invalidas)\n",
        "\n",
        "def guardar_aprendizaje(nueva_pregunta, nueva_respuesta):\n",
        "    global intents\n",
        "\n",
        "    if not respuesta_valida(nueva_respuesta):\n",
        "        return\n",
        "\n",
        "    intencion_predicha = predecir_intencion(nueva_pregunta)\n",
        "\n",
        "    if intencion_predicha:\n",
        "        for intent in intents[\"intents\"]:\n",
        "            if intent[\"tag\"] == intencion_predicha:\n",
        "                if nueva_pregunta not in intent[\"patterns\"]:\n",
        "                    intent[\"patterns\"].append(nueva_pregunta)\n",
        "                if nueva_respuesta not in intent[\"responses\"]:\n",
        "                    intent[\"responses\"].append(nueva_respuesta)\n",
        "                break\n",
        "    else:\n",
        "        nueva_categoria = f\"aprendizaje_{len(intents['intents'])+1}\"\n",
        "        intents[\"intents\"].append({\n",
        "            \"tag\": nueva_categoria,\n",
        "            \"patterns\": [nueva_pregunta],\n",
        "            \"responses\": [nueva_respuesta]\n",
        "        })\n",
        "\n",
        "    with open(archivo_intents, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(intents, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "def manejar_contexto(texto):\n",
        "    global memoria_chat\n",
        "    memoria_chat.append(texto)\n",
        "    if len(memoria_chat) > 3:\n",
        "        memoria_chat.pop(0)\n",
        "    return \" \".join(memoria_chat)\n",
        "\n",
        "def responder_chatbot(texto):\n",
        "    texto_con_contexto = manejar_contexto(texto)\n",
        "    intencion = predecir_intencion(texto_con_contexto)\n",
        "    respuesta = obtener_respuesta_json(intencion)\n",
        "\n",
        "    if respuesta:\n",
        "        return respuesta\n",
        "\n",
        "    for celular in celulares:\n",
        "        if any(palabra in texto.lower() for palabra in [celular[\"Company Name\"].lower(), celular[\"Model Name\"].lower()]):\n",
        "            return json.dumps(celular, indent=4)\n",
        "\n",
        "    respuesta_generada = generar_respuesta_transformer(texto_con_contexto)\n",
        "\n",
        "    if respuesta_valida(respuesta_generada):\n",
        "        guardar_aprendizaje(texto, respuesta_generada)\n",
        "\n",
        "    return respuesta_generada\n",
        "\n",
        "# FunciÃ³n para evaluar el chatbot\n",
        "def evaluar_chatbot(preguntas_evaluacion, respuestas_esperadas):\n",
        "    respuestas_predichas = [responder_chatbot(pregunta) for pregunta in preguntas_evaluacion]\n",
        "\n",
        "    # Convertir las etiquetas de texto a numÃ©ricas para la evaluaciÃ³n\n",
        "    y_true = [predecir_intencion(pregunta) for pregunta in preguntas_evaluacion]\n",
        "    y_pred = [predecir_intencion(respuesta) for respuesta in respuestas_predichas]\n",
        "\n",
        "    y_true_encoded = label_encoder.transform(y_true)\n",
        "    y_pred_encoded = label_encoder.transform(y_pred)\n",
        "\n",
        "    accuracy = accuracy_score(y_true_encoded, y_pred_encoded)\n",
        "    precision = precision_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "\n",
        "    print(f\"PrecisiÃ³n (Accuracy): {accuracy:.2f}\")\n",
        "    print(f\"PrecisiÃ³n (Precision): {precision:.2f}\")\n",
        "\n",
        "# Ejemplo de preguntas y respuestas para la evaluaciÃ³n\n",
        "preguntas_evaluacion = [\n",
        "    \"Â¿QuÃ© tipo de pantalla tiene el iPhone 13?\",\n",
        "    \"Â¿CuÃ¡nto cuesta el Samsung Galaxy S22?\",\n",
        "    \"Â¿QuÃ© procesador tiene el Xiaomi Redmi Note 11?\",\n",
        "    \"Â¿CuÃ¡ntos megapÃ­xeles tiene la cÃ¡mara del Google Pixel 6?\",\n",
        "    \"Â¿Tiene el OnePlus 10 Pro carga rÃ¡pida?\",\n",
        "    \"Â¿QuÃ© versiÃ³n de Android tiene el Samsung Galaxy A53?\",\n",
        "    \"Â¿Es resistente al agua el iPhone 13 Pro?\",\n",
        "    \"Â¿Tiene el Xiaomi 12 lector de huellas digitales?\",\n",
        "    \"Â¿QuÃ© celulares tienen 5G?\",\n",
        "    \"Â¿QuÃ© celulares tienen buena cÃ¡mara para selfies?\",\n",
        "    \"Â¿CuÃ¡l es el mejor celular para juegos?\",\n",
        "    \"Â¿QuÃ© celular tiene la mejor baterÃ­a?\",\n",
        "    \"Â¿QuÃ© celular tiene la mejor cÃ¡mara?\",\n",
        "    \"Â¿QuÃ© celular tiene la mejor pantalla?\",\n",
        "    \"Â¿QuÃ© celular es el mÃ¡s resistente?\",\n",
        "    \"Â¿QuÃ© celular tiene la mejor relaciÃ³n calidad-precio?\",\n",
        "    \"Â¿QuÃ© celular tiene la mejor conectividad?\",\n",
        "    \"Â¿QuÃ© celular tiene la mejor seguridad?\",\n",
        "    \"Â¿QuÃ© celular tiene la mejor experiencia de usuario?\",\n",
        "    \"Â¿QuÃ© celular tiene el mejor diseÃ±o?\",\n",
        "    \"Â¿QuÃ© celulares tienen pantalla AMOLED?\",\n",
        "    \"Â¿QuÃ© celulares tienen 120Hz?\",\n",
        "    \"Â¿QuÃ© celulares tienen carga inalÃ¡mbrica?\",\n",
        "    \"Â¿QuÃ© celulares tienen zoom Ã³ptico?\",\n",
        "    \"Â¿QuÃ© celulares tienen altavoces estÃ©reo?\",\n",
        "    \"Â¿QuÃ© celulares tienen jack de auriculares?\",\n",
        "    \"Â¿QuÃ© celulares tienen ranura para tarjeta microSD?\",\n",
        "    \"Â¿QuÃ© celulares tienen lÃ¡piz Ã³ptico?\",\n",
        "    \"Â¿QuÃ© celulares tienen pantalla plegable?\",\n",
        "    \"Â¿QuÃ© celulares tienen pantalla curva?\",\n",
        "    \"Â¿QuÃ© celulares tienen notch?\",\n",
        "    \"Â¿QuÃ© celulares tienen agujero en pantalla?\",\n",
        "    \"Â¿QuÃ© celulares tienen cÃ¡mara frontal debajo de la pantalla?\",\n",
        "    \"Â¿QuÃ© celulares tienen cÃ¡mara TOF?\",\n",
        "    \"Â¿QuÃ© celulares tienen sensor LiDAR?\",\n",
        "    \"Â¿QuÃ© celulares tienen sensor de ritmo cardÃ­aco?\",\n",
        "    \"Â¿QuÃ© celulares tienen sensor de temperatura?\",\n",
        "    \"Â¿QuÃ© celulares tienen sensor de luz ultravioleta?\",\n",
        "    \"Â¿QuÃ© celulares tienen sensor de huellas dactilares ultrasÃ³nico?\",\n",
        "    \"Â¿QuÃ© celulares tienen sensor de huellas dactilares Ã³ptico?\"\n",
        "]\n",
        "\n",
        "respuestas_esperadas = [\n",
        "    \"El iPhone 13 tiene una pantalla OLED Super Retina XDR de 6.1 pulgadas.\",\n",
        "    \"El precio del Samsung Galaxy S22 varÃ­a segÃºn la configuraciÃ³n, pero ronda los $799.\",\n",
        "    \"El Xiaomi Redmi Note 11 tiene un procesador Qualcomm Snapdragon 680.\",\n",
        "    \"La cÃ¡mara principal del Google Pixel 6 tiene 50 megapÃ­xeles.\",\n",
        "    \"SÃ­, el OnePlus 10 Pro tiene carga rÃ¡pida SuperVOOC de 80W.\",\n",
        "    \"El Samsung Galaxy A53 viene con Android 12.\",\n",
        "    \"SÃ­, el iPhone 13 Pro es resistente al agua con certificaciÃ³n IP68.\",\n",
        "    \"SÃ­, el Xiaomi 12 tiene lector de huellas digitales en pantalla.\",\n",
        "    \"Algunos celulares con 5G son: iPhone 13, Samsung Galaxy S22, Xiaomi 12, Google Pixel 6, OnePlus 10 Pro.\",\n",
        "    \"Algunos celulares con buena cÃ¡mara para selfies son: Google Pixel 6, iPhone 13, Samsung Galaxy S22.\",\n",
        "    \"El mejor celular para juegos depende de tus preferencias, pero algunos modelos populares son el Asus ROG Phone 6, el RedMagic 7S Pro y el iPhone 14 Pro Max.\",\n",
        "    \"El celular con la mejor baterÃ­a depende de tus necesidades, pero algunos modelos con buena autonomÃ­a son el Asus ROG Phone 6, el Motorola Edge+ y el Samsung Galaxy S23 Ultra.\",\n",
        "    \"El celular con la mejor cÃ¡mara depende de tus preferencias, pero algunos modelos con cÃ¡maras destacadas son el Google Pixel 7 Pro, el iPhone 14 Pro Max y el Samsung Galaxy S23 Ultra.\",\n",
        "    \"El celular con la mejor pantalla depende de tus preferencias, pero algunos modelos con pantallas excelentes son el Samsung Galaxy S23 Ultra, el iPhone 14 Pro Max y el Google Pixel 7 Pro.\",\n",
        "    \"El celular mÃ¡s resistente depende de tus necesidades, pero algunos modelos con buena resistencia son el CAT S62 Pro, el Samsung Galaxy XCover 6 Pro y el Doogee S100.\",\n",
        "    \"El celular con la mejor relaciÃ³n calidad-precio depende de tus necesidades y presupuesto, pero algunos modelos populares son el Google Pixel 6a, el Samsung Galaxy A53 y el Xiaomi Redmi Note 11 Pro.\",\n",
        "    \"El celular con la mejor conectividad depende de tus necesidades, pero algunos modelos con buena conectividad son el Samsung Galaxy S23 Ultra, el iPhone 14 Pro Max y el Google Pixel 7 Pro.\",\n",
        "    \"El celular con la mejor seguridad depende de tus necesidades, pero algunos modelos con buena seguridad son el Google Pixel 7 Pro, el iPhone 14 Pro Max y el Samsung Galaxy S23 Ultra.\",\n",
        "    \"El celular con la mejor experiencia de usuario depende de tus preferencias, pero algunos modelos con buena experiencia de usuario son el Google Pixel 7 Pro, el iPhone 14 Pro Max y el Samsung Galaxy S23 Ultra.\",\n",
        "    \"El celular con el mejor diseÃ±o depende de tus preferencias, pero algunos modelos con diseÃ±os atractivos son el Samsung Galaxy S23 Ultra, el iPhone 14 Pro Max y el Google Pixel 7 Pro.\",\n",
        "    \"Algunos celulares con pantalla AMOLED son: Samsung Galaxy S23 Ultra, iPhone 14 Pro Max, Google Pixel 7 Pro, OnePlus 11.\",\n",
        "    \"Algunos celulares con 120Hz son: Samsung Galaxy S23 Ultra, iPhone 14 Pro Max, Google Pixel 7 Pro, OnePlus 11, Xiaomi 13 Pro.\",\n",
        "    \"Algunos celulares con carga inalÃ¡mbrica son: Samsung Galaxy S23 Ultra, iPhone 14 Pro Max, Google Pixel 7 Pro, OnePlus 11, Xiaomi 13 Pro.\",\n",
        "    \"Algunos celulares con zoom Ã³ptico son: Samsung Galaxy S23 Ultra, iPhone 14 Pro Max, Google Pixel 7 Pro, Xiaomi 13 Pro.\",\n",
        "    \"Algunos celulares con altavoces estÃ©reo son: Samsung Galaxy S23 Ultra, iPhone 14 Pro Max, Google Pixel 7 Pro, OnePlus 11, Xiaomi 13 Pro.\",\n",
        "    \"Algunos celulares con jack de auriculares son: Asus ROG Phone 6, Sony Xperia 1 IV, algunos modelos de gama de entrada y media.\",\n",
        "    \"Algunos celulares con ranura para tarjeta microSD son: Algunos modelos de Samsung Galaxy A, algunos modelos de Xiaomi Redmi Note.\",\n",
        "    \"Algunos celulares con lÃ¡piz Ã³ptico son: Samsung Galaxy S23 Ultra, Samsung Galaxy Note 20 Ultra.\",\n",
        "    \"Algunos celulares con pantalla plegable son: Samsung Galaxy Z Fold 4, Samsung Galaxy Z Flip 4, Motorola Razr 2022.\",\n",
        "    \"Algunos celulares con pantalla curva son: Samsung Galaxy S23 Ultra, OnePlus 11, Xiaomi 13 Pro.\",\n",
        "    \"Algunos celulares con notch son: iPhone 13, iPhone 12, algunos modelos de gama de entrada y media.\",\n",
        "    \"Algunos celulares con agujero en pantalla son: Samsung Galaxy S23 Ultra, Google Pixel 7 Pro, OnePlus 11, Xiaomi 13 Pro.\",\n",
        "    \"Algunos celulares con cÃ¡mara frontal debajo de la pantalla son: Samsung Galaxy Z Fold 4, Xiaomi Mix 4.\",\n",
        "    \"Algunos celulares con cÃ¡mara TOF son: Algunos modelos de gama alta de Huawei, algunos modelos de gama alta de Samsung.\",\n",
        "    \"Algunos celulares con sensor LiDAR son: iPhone 14 Pro Max, iPhone 13 Pro Max, iPad Pro.\",\n",
        "    \"Algunos celulares con sensor de ritmo cardÃ­aco son: Algunos modelos de Samsung Galaxy Watch.\",\n",
        "    \"Algunos celulares con sensor de temperatura son: Algunos modelos de Huawei Watch.\",\n",
        "    \"Algunos celulares con sensor de luz ultravioleta son: Algunos modelos de Samsung Galaxy S.\",\n",
        "    \"Algunos celulares con sensor de huellas dactilares ultrasÃ³nico son: Samsung Galaxy S23 Ultra, Samsung Galaxy S22 Ultra.\",\n",
        "    \"Algunos celulares con sensor de huellas dactilares Ã³ptico son: Google Pixel 7 Pro, OnePlus 11, Xiaomi 13 Pro.\"\n",
        "]\n",
        "evaluar_chatbot(preguntas_evaluacion, respuestas_esperadas)\n",
        "\n",
        "\n",
        "while True:\n",
        "    pregunta = input(\"ðŸ‘¤ Escribe tu consulta (o 'salir' para terminar): \")\n",
        "    if pregunta.lower() == \"salir\":\n",
        "        break\n",
        "    print(\"ðŸ¤–\", responder_chatbot(pregunta))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd8pTjVZhcnC",
        "outputId": "be50d991-b003-4114-cdf3-606a06e9c461"
      },
      "execution_count": 41,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PrecisiÃ³n (Accuracy): 0.78\n",
            "PrecisiÃ³n (Precision): 0.60\n",
            "ðŸ‘¤ Escribe tu consulta (o 'salir' para terminar): celular Samsung\n",
            "ðŸ¤–  I have an iphone 7 and I love it. It's the best phone I've ever owned.\n",
            "ðŸ‘¤ Escribe tu consulta (o 'salir' para terminar): en espaÃ±ol\n",
            "ðŸ¤–  I'm not sure what you mean by that, but I do know that celery is a type of fruit.\n",
            "ðŸ‘¤ Escribe tu consulta (o 'salir' para terminar): Â¿cual es el mejor telefono para gaming?\n",
            "ðŸ¤–  I'm not sure what you mean by that, but I do know that celery is a type of fruit.\n",
            "ðŸ‘¤ Escribe tu consulta (o 'salir' para terminar): salir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pfkngOOOhcY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.0 con parametros del intents.json"
      ],
      "metadata": {
        "id": "TZJJxwD7h5Fs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score  # MÃ©tricas de evaluaciÃ³n\n",
        "\n",
        "# Cargar modelos de Hugging Face\n",
        "modelo_emb_name = \"distilbert-base-uncased\"\n",
        "modelo_resp_name = \"facebook/blenderbot-400M-distill\"\n",
        "\n",
        "tokenizer_emb = AutoTokenizer.from_pretrained(modelo_emb_name)\n",
        "modelo_emb = AutoModel.from_pretrained(modelo_emb_name)\n",
        "\n",
        "tokenizer_resp = AutoTokenizer.from_pretrained(modelo_resp_name)\n",
        "modelo_resp = AutoModelForSeq2SeqLM.from_pretrained(modelo_resp_name)\n",
        "\n",
        "# Cargar el dataset del chatbot (intents.json)\n",
        "archivo_intents = \"intents.json\"\n",
        "try:\n",
        "    with open(archivo_intents, \"r\", encoding=\"utf-8\") as file:\n",
        "        intents = json.load(file)\n",
        "except FileNotFoundError:\n",
        "    intents = {\"intents\": []}\n",
        "\n",
        "# Cargar dataset de celulares\n",
        "archivo_celulares = \"celulares_limpios.json\"\n",
        "try:\n",
        "    with open(archivo_celulares, \"r\", encoding=\"utf-8\") as file:\n",
        "        celulares = json.load(file)\n",
        "except FileNotFoundError:\n",
        "    celulares = []\n",
        "\n",
        "# Memoria de la conversaciÃ³n (para recordar contexto)\n",
        "memoria_chat = []\n",
        "\n",
        "def obtener_embedding(frase):\n",
        "    tokens = tokenizer_emb(frase, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
        "    with torch.no_grad():\n",
        "        salida = modelo_emb(**tokens)\n",
        "    return salida.last_hidden_state[:, 0, :].numpy().flatten()\n",
        "\n",
        "patterns, labels = [], []\n",
        "\n",
        "for intent in intents[\"intents\"]:\n",
        "    if \"tag\" in intent and \"patterns\" in intent:\n",
        "        for pattern in intent[\"patterns\"]:\n",
        "            patterns.append(pattern)\n",
        "            labels.append(intent[\"tag\"])\n",
        "\n",
        "if patterns:\n",
        "    X = np.array([obtener_embedding(frase) for frase in patterns])\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(labels)\n",
        "\n",
        "    classifier = SVC(kernel=\"linear\", probability=True)\n",
        "    classifier.fit(X, y)\n",
        "else:\n",
        "    classifier = None\n",
        "\n",
        "def predecir_intencion(frase):\n",
        "    if classifier:\n",
        "        embedding = obtener_embedding(frase)\n",
        "        prediccion = classifier.predict([embedding])[0]\n",
        "        return label_encoder.inverse_transform([prediccion])[0]\n",
        "    return None\n",
        "\n",
        "def obtener_respuesta_json(intencion):\n",
        "    for intent in intents[\"intents\"]:\n",
        "        if intent[\"tag\"] == intencion:\n",
        "            return np.random.choice(intent[\"responses\"])\n",
        "    return None\n",
        "\n",
        "def generar_respuesta_transformer(frase):\n",
        "    tokens = tokenizer_resp(frase, return_tensors=\"pt\", padding=True, truncation=True, max_length=64)\n",
        "    with torch.no_grad():\n",
        "        respuesta_ids = modelo_resp.generate(**tokens)\n",
        "    return tokenizer_resp.decode(respuesta_ids[0], skip_special_tokens=True)\n",
        "\n",
        "def respuesta_valida(respuesta):\n",
        "    palabras_invalidas = [\"no sÃ©\", \"no entiendo\", \"no puedo ayudar\", \"no tengo informaciÃ³n\"]\n",
        "    return not any(palabra in respuesta.lower() for palabra in palabras_invalidas)\n",
        "\n",
        "def guardar_aprendizaje(nueva_pregunta, nueva_respuesta):\n",
        "    global intents\n",
        "\n",
        "    if not respuesta_valida(nueva_respuesta):\n",
        "        return\n",
        "\n",
        "    intencion_predicha = predecir_intencion(nueva_pregunta)\n",
        "\n",
        "    if intencion_predicha:\n",
        "        for intent in intents[\"intents\"]:\n",
        "            if intent[\"tag\"] == intencion_predicha:\n",
        "                if nueva_pregunta not in intent[\"patterns\"]:\n",
        "                    intent[\"patterns\"].append(nueva_pregunta)\n",
        "                if nueva_respuesta not in intent[\"responses\"]:\n",
        "                    intent[\"responses\"].append(nueva_respuesta)\n",
        "                break\n",
        "    else:\n",
        "        nueva_categoria = f\"aprendizaje_{len(intents['intents'])+1}\"\n",
        "        intents[\"intents\"].append({\n",
        "            \"tag\": nueva_categoria,\n",
        "            \"patterns\": [nueva_pregunta],\n",
        "            \"responses\": [nueva_respuesta]\n",
        "        })\n",
        "\n",
        "    with open(archivo_intents, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(intents, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "def manejar_contexto(texto):\n",
        "    global memoria_chat\n",
        "    memoria_chat.append(texto)\n",
        "    if len(memoria_chat) > 3:\n",
        "        memoria_chat.pop(0)\n",
        "    return \" \".join(memoria_chat)\n",
        "\n",
        "def responder_chatbot(texto):\n",
        "    texto_con_contexto = manejar_contexto(texto)\n",
        "    intencion = predecir_intencion(texto_con_contexto)\n",
        "    respuesta = obtener_respuesta_json(intencion)\n",
        "\n",
        "    if respuesta:\n",
        "        return respuesta\n",
        "\n",
        "    for celular in celulares:\n",
        "        if any(palabra in texto.lower() for palabra in [celular[\"Company Name\"].lower(), celular[\"Model Name\"].lower()]):\n",
        "            return json.dumps(celular, indent=4)\n",
        "\n",
        "    respuesta_generada = generar_respuesta_transformer(texto_con_contexto)\n",
        "\n",
        "    if respuesta_valida(respuesta_generada):\n",
        "        guardar_aprendizaje(texto, respuesta_generada)\n",
        "\n",
        "    return respuesta_generada\n",
        "\n",
        "# FunciÃ³n para evaluar el chatbot\n",
        "def evaluar_chatbot(preguntas_evaluacion, respuestas_esperadas):\n",
        "    respuestas_predichas = [responder_chatbot(pregunta) for pregunta in preguntas_evaluacion]\n",
        "\n",
        "    # Convertir las etiquetas de texto a numÃ©ricas para la evaluaciÃ³n\n",
        "    y_true = [predecir_intencion(pregunta) for pregunta in preguntas_evaluacion]\n",
        "    y_pred = [predecir_intencion(respuesta) for respuesta in respuestas_predichas]\n",
        "\n",
        "    y_true_encoded = label_encoder.transform(y_true)\n",
        "    y_pred_encoded = label_encoder.transform(y_pred)\n",
        "\n",
        "    accuracy = accuracy_score(y_true_encoded, y_pred_encoded)\n",
        "    precision = precision_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_true_encoded, y_pred_encoded, average='weighted', zero_division=0)\n",
        "\n",
        "    print(f\"PrecisiÃ³n (Accuracy): {accuracy:.2f}\")\n",
        "    print(f\"PrecisiÃ³n (Precision): {precision:.2f}\")\n",
        "\n",
        "# Ejemplo de preguntas y respuestas para la evaluaciÃ³n\n",
        "\n",
        "preguntas_evaluacion = [\n",
        "    # IntenciÃ³n \"saludo\"\n",
        "    \"Hola\",\n",
        "    \"Â¿CÃ³mo estÃ¡s?\",\n",
        "    \"Buenos dÃ­as\",\n",
        "    \"Â¡QuÃ© tal!\",\n",
        "    \"Hey\",\n",
        "    \"Â¿QuÃ© onda?\",\n",
        "    \"Dame saludos\",\n",
        "    \"Â¿Me saludas?\",\n",
        "\n",
        "    # IntenciÃ³n \"despedida\"\n",
        "    \"AdiÃ³s\",\n",
        "    \"Hasta luego\",\n",
        "    \"Nos vemos\",\n",
        "    \"Chao\",\n",
        "    \"Me voy\",\n",
        "    \"Bye\",\n",
        "    \"Hasta la vista\",\n",
        "    \"CuÃ­date\",\n",
        "    \"Debo irme\",\n",
        "    \"DespÃ­dete\",\n",
        "\n",
        "    # IntenciÃ³n \"agradecimientos\"\n",
        "    \"gracias\",\n",
        "    \"muchas gracias\",\n",
        "    \"mil gracias\",\n",
        "    \"muy amable\",\n",
        "    \"se lo agradezco\",\n",
        "    \"fue de ayuda\",\n",
        "    \"gracias por la ayuda\",\n",
        "    \"muy agradecido\",\n",
        "    \"gracias por tu tiempo\",\n",
        "    \"gracias por responder\",\n",
        "    \"Te agradezco mucho\",\n",
        "\n",
        "    # IntenciÃ³n \"celulares_para_juegos\"\n",
        "    \"jugar\",\n",
        "    \"gaming\",\n",
        "    \"potente para juegos\",\n",
        "    \"rendimiento en juegos\",\n",
        "    \"TelÃ©fonos gaming\",\n",
        "    \"Me gustan los juegos\",\n",
        "    \"para jugar\",\n",
        "    \"buena GPU\",\n",
        "    \"mejor celular gamer\",\n",
        "    \"Â¿QuÃ© celular es bueno para jugar?\",\n",
        "\n",
        "    # IntenciÃ³n \"cÃ¡mara_y_fotografia\"\n",
        "    \"buena cÃ¡mara\",\n",
        "    \"tomar fotos\",\n",
        "    \"cÃ¡mara de alta calidad\",\n",
        "    \"mejor cÃ¡mara\",\n",
        "    \"fotografÃ­a\",\n",
        "    \"fotos profesionales\",\n",
        "    \"buen zoom\",\n",
        "    \"cÃ¡mara nocturna\",\n",
        "    \"estabilizaciÃ³n Ã³ptica\",\n",
        "    \"cÃ¡mara frontal\",\n",
        "    \"Â¿QuÃ© celular tiene buena cÃ¡mara para fotos?\",\n",
        "\n",
        "    # IntenciÃ³n \"resistencia_y_durabilidad\"\n",
        "    \"resistente\",\n",
        "    \"no se rompa\",\n",
        "    \"Â¡Hola! Â¿En quÃ© puedo ayudarte hoy?\",\n",
        "    \"Â¡Saludos! Â¿QuÃ© necesitas?\",\n",
        "    \"Â¡Hey! Â¿CÃ³mo estÃ¡s?\",\n",
        "    \"Â¡QuÃ© gusto verte!\",\n",
        "\n",
        "\n",
        "    # IntenciÃ³n \"despedida\"\n",
        "    \"Â¡Hasta luego! Que tengas un buen dÃ­a.\",\n",
        "    \"Â¡AdiÃ³s! Â¡Vuelve pronto!\",\n",
        "    \"Â¡Nos vemos! No dudes en preguntar cuando lo necesites.\",\n",
        "    \"Â¡CuÃ­date!\",\n",
        "    \"Bye, hasta la prÃ³xima.\",\n",
        "\n",
        "    # IntenciÃ³n \"agradecimientos\"\n",
        "    \"De nada, estoy aquÃ­ para ayudar.\",\n",
        "    \"Feliz por ayudar.\",\n",
        "    \"Gracias a ti por preguntar.\",\n",
        "    \"Â¡Siempre a la orden!\",\n",
        "    \"Fue un placer ayudarte.\",\n",
        "\n",
        "    # IntenciÃ³n \"celulares_para_juegos\"\n",
        "    \"Para gaming, te recomiendo un celular con un buen procesador y al menos 8GB de RAM.\",\n",
        "    \"Los telÃ©fonos con Snapdragon 8 Gen 2 y buena tasa de refresco son ideales para juegos.\",\n",
        "    \"Busca un celular con una GPU potente y refrigeraciÃ³n eficiente.\",\n",
        "    \"Algunos celulares gaming incluyen botones fÃ­sicos y triggers.\",\n",
        "    \"Â¿Tienes un presupuesto en mente? Puedo recomendarte algo segÃºn tu rango de precio.\",\n",
        "    # IntenciÃ³n \"cÃ¡mara_y_fotografÃ­a\"\n",
        "    \"Para fotografÃ­a, te sugiero un celular con al menos 50MP en la cÃ¡mara principal y buen procesamiento de imagen.\",\n",
        "    \"Los celulares de gama alta suelen tener mejores cÃ¡maras, pero hay opciones mÃ¡s accesibles con buenas prestaciones.\",\n",
        "    \"Busca un celular con estabilizaciÃ³n Ã³ptica para mejores fotos en movimiento.\",\n",
        "    \"Algunos modelos cuentan con teleobjetivo para capturas a larga distancia.\",\n",
        "    \"Â¿Prefieres un celular con cÃ¡mara profesional o algo mÃ¡s equilibrado?\",\n",
        "\n",
        "    # IntenciÃ³n \"resistencia_y_durabilidad\"\n",
        "    \"Si buscas un celular resistente, te recomiendo modelos con certificaciÃ³n IP68 o con protecciÃ³n militar.\",\n",
        "                \"Algunos celulares como los CAT o Samsung XCover estÃ¡n diseÃ±ados para resistir golpes y polvo.\",\n",
        "                \"Los celulares con Gorilla Glass suelen tener pantallas mÃ¡s resistentes.\",\n",
        "                \"Si trabajas en ambientes exigentes, te sugiero un smartphone todoterreno.\",\n",
        "    # IntenciÃ³n \"trabajo_y_productividad\"\n",
        "    \"Si buscas un celular para trabajo, te sugiero modelos con buena baterÃ­a y almacenamiento amplio.\",\n",
        "                \"Algunos modelos premium incluyen funciones especÃ­ficas para productividad como Samsung Dex o Apple Continuity.\",\n",
        "                \"Si necesitas tomar notas, te recomiendo un celular con lÃ¡piz Ã³ptico como la serie Galaxy Note o S Ultra.\",\n",
        "                \"Â¿Buscas algo potente o mÃ¡s enfocado en baterÃ­a y conectividad?\",\n",
        "\n",
        "    # IntenciÃ³n \"software_y_actualizaciones\"\n",
        "    \"Si buscas un celular con actualizaciones garantizadas, los Google Pixel y Samsung tienen buen soporte.\",\n",
        "                \"Apple ofrece soporte de software por mÃ¡s aÃ±os que la mayorÃ­a de marcas de Android.\",\n",
        "                \"Si te preocupa la seguridad, busca celulares con parches de seguridad mensuales.\",\n",
        "                \"Los celulares con Android puro suelen recibir actualizaciones mÃ¡s rÃ¡pido que los personalizados.\",\n",
        "\n",
        "    # IntenciÃ³n \"celulares_por_marca\"\n",
        "    \"Claro, aquÃ­ tienes modelos de la marca que buscas.\",\n",
        "                \"Estos son algunos de los mejores celulares de esa marca.\",\n",
        "                \"DÃ©jame filtrar los modelos disponibles de esa marca.\",\n",
        "                \"Los celulares de esta marca tienen diferentes opciones, Â¿buscas algo en especÃ­fico?\",\n",
        "                \"Puedo mostrarte los Ãºltimos lanzamientos o modelos populares de esa marca.\",\n",
        "\n",
        "    # IntenciÃ³n \"pantalla_y_calidad\"\n",
        "    \"Si buscas una pantalla grande, te recomendarÃ­a un modelo con mÃ¡s de 6.5 pulgadas.\",\n",
        "                \"Las pantallas AMOLED ofrecen mejor contraste y colores mÃ¡s vivos.\",\n",
        "                \"Los celulares con 120Hz ofrecen una experiencia mÃ¡s fluida al navegar y jugar.\",\n",
        "                \"Si quieres la mejor calidad de pantalla, busca modelos con HDR10 o Dolby Vision.\",\n",
        "                \"Â¿Te interesa mÃ¡s la calidad de imagen o el tamaÃ±o de la pantalla?\",\n",
        "\n",
        "    # IntenciÃ³n \"celulares_nuevos_y_antiguos\"\n",
        "    \"AquÃ­ tienes una lista de los celulares mÃ¡s recientes.\",\n",
        "                \"Estos son algunos modelos lanzados en los Ãºltimos meses.\",\n",
        "                \"Si buscas lo Ãºltimo en tecnologÃ­a, estos celulares pueden interesarte.\",\n",
        "                \"Â¿Te gustarÃ­a un modelo de gama alta o prefieres algo mÃ¡s asequible?\",\n",
        "                \"DÃ©jame buscar los modelos mÃ¡s recientes en nuestra base de datos.\",\n",
        " ]\n",
        "evaluar_chatbot(preguntas_evaluacion, respuestas_esperadas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G_dxwalh4zx",
        "outputId": "09f08839-298a-44c6-9f2d-1e4fde15e136"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PrecisiÃ³n (Accuracy): 0.57\n",
            "PrecisiÃ³n (Precision): 0.52\n"
          ]
        }
      ]
    }
  ]
}